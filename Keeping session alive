def _get_target_features(df, target_columns):
    """
    Extract industry-standard profiling features for anomaly detection.
    
    Args:
        df: DataFrame containing profiling metrics
        target_columns: List of base column names to monitor
        
    Returns:
        List of selected feature column names
    """
    
    # Core metrics (mandatory for anomaly detection)
    core_suffixes = [
        '_Mean',                    # Distribution center
        '_StandardDeviation',       # Variability measure
        '_CountDistinct',          # Cardinality tracking
        '_Completeness'            # Data quality indicator
    ]
    
    # Secondary metrics (data type specific)
    secondary_suffixes = [
        '_ApproxQuantiles_0.5',    # Median (robust to outliers)
        '_UniqueValueRatio',       # Diversity measure
        '_MaxLength'               # String length tracking
    ]
    
    # Combine all feature suffixes
    all_suffixes = core_suffixes + secondary_suffixes
    
    # Create case-insensitive column lookup for efficient matching
    col_lookup = {col.lower(): col for col in df.columns}
    
    features = []
    
    print(f"Processing {len(target_columns)} target columns...")
    
    for base_col in target_columns:
        base_lower = base_col.lower()
        
        # Find all profiling columns for this base column
        matching_cols = [
            actual_col for lower_col, actual_col in col_lookup.items()
            if lower_col.startswith(base_lower) and lower_col.endswith('_met_value')
        ]
        
        if not matching_cols:
            print(f"Warning: No profiling data found for column '{base_col}'")
            continue
            
        # Extract feature columns for each profiling column
        for col in matching_cols:
            col_base = col[:-10]  # Remove '_met_value' suffix
            
            # Build feature names and check availability
            for suffix in all_suffixes:
                feature_name = f"{col_base}{suffix}_met_value"
                
                if feature_name.lower() in col_lookup:
                    features.append(col_lookup[feature_name.lower()])
    
    # Remove duplicates while preserving order
    unique_features = list(dict.fromkeys(features))
    
    # Output summary
    print(f"\nSelected {len(unique_features)} features from {len(target_columns)} target columns")
    print(f"Average features per column: {len(unique_features) / len(target_columns):.1f}")
    
    print("\nSelected features:")
    for i, feature in enumerate(unique_features, 1):
        print(f"  {i:2d}. {feature}")
    
    return unique_features
