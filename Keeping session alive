
import org.apache.spark.sql.SparkSession

def getPartitionColumns(spark: SparkSession, tableName: String): Seq[String] = {
  // Execute 'SHOW CREATE TABLE' command to get the table's DDL
  val createTableDDL = spark.sql(s"SHOW CREATE TABLE $tableName").collect().map(_.getString(0)).mkString("\n")

  // Extract the partition column details from the DDL
  val partitionPattern = "(?i)PARTITIONED BY\\s*\\(([^)]+)\\)".r
  partitionPattern.findFirstMatchIn(createTableDDL) match {
    case Some(matched) => 
      val partitionPart = matched.group(1)
      partitionPart.split(",").map(_.trim.split("\\s+")(0)) // Extracting column names
    case None => 
      Array[String]() // Return an empty array if the table is not partitioned
  }
}

// Usage
val spark: SparkSession = // your SparkSession
val tableName = "your_table_name"
val partitionColumns = getPartitionColumns(spark, tableName)
partitionColumns.foreach(println)


===================================================
import org.apache.spark.sql.DataFrame
import scala.util.matching.Regex

def isString(value: String): Boolean = {
    val stringPattern: Regex = "^[A-Za-z]+$".r
    stringPattern.findFirstIn(value).isDefined
}

def isLikelyDate(value: String): Boolean = {
    // Define regex patterns for various date formats
    val datePatterns = List("\\d{8}", "\\d{6}", "\\d{4}") // yyyymmdd, yyyymm, yyyy

    // Check if the value matches any of the date patterns
    datePatterns.exists(pattern => value.matches(pattern))
}

def validatePartitionColumns(df: DataFrame, partitionColumns: Array[String]): Array[String] = {
    partitionColumns.filter { col =>
        // Cast the column to string and get the first value, filtering out non-digit characters
        val sampleValue = df.select(col).cast("string").first().getString(0).filter(_.isDigit)

        // Determine if the value is likely a date or a string
        !isLikelyDate(sampleValue) && !isString(sampleValue)
    }
}

// Usage
val df1: DataFrame = // Your DataFrame
val partitionColumns = Array("example_date_column", "example_string_column") // Replace with actual column names
val validatedColumns = validatePartitionColumns(df1, partitionColumns)

// Example to print validated columns
validatedColumns.foreach(println)

===

