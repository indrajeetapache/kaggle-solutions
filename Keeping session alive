import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions.count

val spark: SparkSession = // Initialize your Spark session

// Assuming these are your initial arrays
val array1: Array[String] = Array("A", "B", "C", "D")
val array2: Array[String] = Array("B", "D")
val resultArray = array1.diff(array2)

// Assuming df is your DataFrame
val df: DataFrame = // Your DataFrame
val selectedDf = df.select(resultArray.head, resultArray.tail: _*)

val columnName = "YourColumnName"
val duplicates = selectedDf.groupBy(columnName)
  .agg(count(columnName).alias("count"))
  .filter($"count" > 1)

duplicates.show()
