"""
Production-Ready SHAP Explainability for LSTM Anomaly Detection

Purpose: Generate interpretable explanations for anomalies detected by LSTM autoencoder
Audience: Technical teams and executives
Output: Global feature importance, local explanations, and executive summary
"""

import numpy as np
import pandas as pd
import shap
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime
import torch
import warnings
warnings.filterwarnings('ignore')

class SHAPAnomalyExplainer:
    """
    SHAP-based explainability for LSTM autoencoder anomaly detection.
    
    Generates global feature importance and local explanations for anomalies.
    Outputs production-ready reports with visualizations and CSV exports.
    """
    
    def __init__(self, model, scaler, feature_names, seq_length, device='cpu'):
        """
        Initialize explainer with trained model.
        
        Args:
            model: Trained LSTMAutoencoder (PyTorch)
            scaler: Fitted StandardScaler from training
            feature_names: List of feature column names
            seq_length: Sequence length used in training
            device: torch device ('cpu' or 'cuda')
        """
        self.model = model
        self.scaler = scaler
        self.feature_names = feature_names
        self.seq_length = seq_length
        self.device = device
        self.model.eval()
        
        print(f"SHAPAnomalyExplainer initialized:")
        print(f"  - Features: {len(feature_names)}")
        print(f"  - Sequence length: {seq_length}")
        print(f"  - Device: {device}")
    
    def _create_background_data(self, normal_sequences, n_samples=100):
        """
        Create background dataset for SHAP from normal sequences.
        
        Background data represents "typical" model behavior for SHAP baselines.
        Uses stratified sampling across the time series to capture variability.
        
        Args:
            normal_sequences: Array of normal sequences [N, seq_len, features]
            n_samples: Number of background samples (default 100, SHAP recommended)
        
        Returns:
            Background sequences for SHAP explainer
        """
        n_total = len(normal_sequences)
        n_samples = min(n_samples, n_total)
        
        # Stratified sampling: take samples evenly across time
        indices = np.linspace(0, n_total-1, n_samples, dtype=int)
        background = normal_sequences[indices]
        
        print(f"Created background dataset: {background.shape}")
        return background
        
    def validate_shap_quality(self, shap_values, test_sequences):
        """
        Validate SHAP output quality and detect potential issues.
        
        Checks for:
        - NaN/Inf values (computation errors)
        - High feature correlation (SHAP attribution ambiguity)
        - Low-variance features (noise/irrelevant features)
        
        Args:
            shap_values: SHAP values [N, features]
            test_sequences: Original sequences [N, seq_len, features]
        
        Returns:
            validation_report: Dict with warnings and quality metrics
        """
        report = {
            'status': 'PASS',
            'warnings': [],
            'metrics': {}
        }
        
        # Check 1: NaN/Inf detection
        nan_count = np.isnan(shap_values).sum()
        inf_count = np.isinf(shap_values).sum()
        
        if nan_count > 0:
            report['status'] = 'FAIL'
            report['warnings'].append(f"Found {nan_count} NaN values in SHAP output")
        
        if inf_count > 0:
            report['status'] = 'FAIL'
            report['warnings'].append(f"Found {inf_count} Inf values in SHAP output")
        
        report['metrics']['nan_count'] = int(nan_count)
        report['metrics']['inf_count'] = int(inf_count)
        
        # Check 2: Low-variance features (likely noise)
        shap_std = np.std(shap_values, axis=0)
        low_variance_threshold = 0.001
        low_variance_features = np.where(shap_std < low_variance_threshold)[0]
        
        if len(low_variance_features) > 0:
            report['warnings'].append(
                f"Found {len(low_variance_features)} low-variance features (std < {low_variance_threshold})"
            )
            report['metrics']['low_variance_features'] = [
                self.feature_names[i] for i in low_variance_features[:10]
            ]
        
        # Check 3: High feature correlation (attribution ambiguity)
        feature_values = test_sequences.mean(axis=1)  # [N, features]
        correlation_matrix = np.corrcoef(feature_values.T)
        
        high_corr_threshold = 0.9
        high_corr_pairs = []
        n_features = len(self.feature_names)
        
        for i in range(n_features):
            for j in range(i+1, n_features):
                if abs(correlation_matrix[i, j]) > high_corr_threshold:
                    high_corr_pairs.append({
                        'feature_1': self.feature_names[i],
                        'feature_2': self.feature_names[j],
                        'correlation': float(correlation_matrix[i, j])
                    })
        
        if len(high_corr_pairs) > 0:
            report['warnings'].append(
                f"Found {len(high_corr_pairs)} highly correlated feature pairs (|corr| > {high_corr_threshold})"
            )
            report['metrics']['high_correlation_pairs'] = high_corr_pairs[:5]
        
        # Check 4: SHAP value range sanity check
        shap_range = (float(np.min(shap_values)), float(np.max(shap_values)))
        shap_mean = float(np.mean(np.abs(shap_values)))
        
        report['metrics']['shap_value_range'] = shap_range
        report['metrics']['mean_abs_shap'] = shap_mean
        
        # Summary
        if report['status'] == 'PASS' and len(report['warnings']) == 0:
            print("\n✓ SHAP quality validation: PASSED")
        else:
            print(f"\n⚠ SHAP quality validation: {report['status']}")
            print(f"  Warnings: {len(report['warnings'])}")
            for warning in report['warnings']:
                print(f"  - {warning}")
        
        return report
        
    def compute_shap_values(self, test_sequences, background_sequences, max_samples=50):
        n_test = min(len(test_sequences), max_samples)
        test_subset = test_sequences[:n_test]
        
        print(f"\nComputing SHAP values for {n_test} samples using GradientExplainer...")
        
        class ReconstructionErrorModel(torch.nn.Module):
            def __init__(self, autoencoder):
                super().__init__()
                self.autoencoder = autoencoder
            
            def forward(self, x):
                reconstructed = self.autoencoder(x)
                mse = torch.mean((x - reconstructed) ** 2, dim=(1, 2))
                return mse.unsqueeze(-1)
        
        wrapper_model = ReconstructionErrorModel(self.model)
        wrapper_model.eval()
        
        background_tensor = torch.FloatTensor(background_sequences).to(self.device)
        test_tensor = torch.FloatTensor(test_subset).to(self.device)
        
        explainer = shap.GradientExplainer(wrapper_model, background_tensor)
        shap_values = explainer.shap_values(test_tensor)
        
        with torch.no_grad():
            base_values = wrapper_model(background_tensor).mean().item()
        
        if isinstance(shap_values, list):
            shap_values = np.array(shap_values[0])
        
        # Remove all dimensions except [samples, features]
        shap_values = np.squeeze(shap_values)  # Remove singleton dims
        
        # Handle different output shapes
        if shap_values.ndim == 3:  # [samples, time, features]
            shap_values = shap_values.mean(axis=1)
        elif shap_values.ndim == 2 and shap_values.shape[0] != n_test:  # [time, features]
            shap_values = shap_values.mean(axis=0, keepdims=True)  # → [1, features]
        elif shap_values.ndim == 1:  # [features]
            shap_values = shap_values.reshape(1, -1)  # → [1, features]
        
        print(f"SHAP computation complete: {shap_values.shape}")
        return shap_values, base_values    

    def global_feature_importance(self, shap_values, top_n=20):
        """
        Calculate global feature importance from SHAP values.
        
        Global importance = mean |SHAP value| across all samples.
        Industry standard for "which features drive anomalies overall?"
        
        Args:
            shap_values: SHAP values [N, features]
            top_n: Number of top features to return
        
        Returns:
            DataFrame with feature rankings and importance scores
        """
        # Mean absolute SHAP value per feature
        importance = np.abs(shap_values).mean(axis=0)
        
        # Create ranking DataFrame
        ranking_df = pd.DataFrame({
            'feature': self.feature_names,
            'mean_abs_shap': importance,
            'importance_rank': range(1, len(importance) + 1)
        }).sort_values('mean_abs_shap', ascending=False).reset_index(drop=True)
        
        # Update ranks
        ranking_df['importance_rank'] = range(1, len(ranking_df) + 1)
        
        print(f"\nTop {top_n} features by global importance:")
        print(ranking_df.head(top_n)[['importance_rank', 'feature', 'mean_abs_shap']])
        
        return ranking_df
    
    
    def generate_executive_summary(self, shap_values, feature_ranking, 
                                anomaly_count, total_samples, top_n=None):
        if top_n is None:
            top_n = min(5, len(feature_ranking))
        
        top_features = feature_ranking.head(top_n)
        top_names = top_features['feature'].tolist()
        top_importance = top_features['mean_abs_shap'].sum()
        total_importance = feature_ranking['mean_abs_shap'].sum()
        
        pct_explained = (top_importance / total_importance) * 100
        anomaly_rate = (anomaly_count / total_samples) * 100
        
        summary = f"""
    === EXECUTIVE SUMMARY: ANOMALY ANALYSIS ===
    Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

    OVERVIEW:
    - Total Samples: {total_samples:,}
    - Anomalies: {anomaly_count} ({anomaly_rate:.2f}%)
    - Features Analyzed: {len(self.feature_names)}

    KEY FINDINGS:
    Top {top_n} features explain {pct_explained:.1f}% of anomalies:
    """
        for i, (name, imp) in enumerate(zip(top_names, top_features['mean_abs_shap']), 1):
            summary += f"\n{i}. {name} (Importance: {imp:.4f})"
        
        summary += f"""

    RECOMMENDATION:
    Focus on top {top_n} features for root cause analysis.
    """
        return summary

    def plot_global_importance(self, feature_ranking, output_dir, top_n=20):
        """
        Create global feature importance bar chart.
        
        Args:
            feature_ranking: Global importance DataFrame
            output_dir: Directory to save plot
            top_n: Number of top features to plot
        """
        top_features = feature_ranking.head(top_n)
        
        plt.figure(figsize=(10, 8))
        plt.barh(range(len(top_features)), top_features['mean_abs_shap'])
        plt.yticks(range(len(top_features)), top_features['feature'])
        plt.xlabel('Mean |SHAP Value| (Feature Importance)', fontsize=12)
        plt.ylabel('Feature', fontsize=12)
        plt.title(f'Top {top_n} Features Driving Anomalies (Global)', fontsize=14, fontweight='bold')
        plt.gca().invert_yaxis()
        plt.tight_layout()
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = Path(output_dir) / f'global_importance_{timestamp}.png'
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"Saved: {filepath}")
        return filepath
    
    def plot_shap_summary(self, shap_values, test_sequences, output_dir, top_n=20):
        """
        Create SHAP beeswarm plot showing feature value impact.
        
        Shows how feature values (low/high) affect model output.
        
        Args:
            shap_values: SHAP values [N, features]
            test_sequences: Original sequences for feature values
            output_dir: Directory to save plot
            top_n: Number of features to display
        """
        # Average feature values across time steps
        feature_values = test_sequences.mean(axis=1)  # [N, features]
        
        plt.figure(figsize=(10, 8))
        shap.summary_plot(
            shap_values, 
            feature_values,
            feature_names=self.feature_names,
            max_display=top_n,
            show=False
        )
        plt.title('SHAP Feature Impact Distribution', fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = Path(output_dir) / f'shap_summary_{timestamp}.png'
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"Saved: {filepath}")
        return filepath
    
    def plot_local_explanation(self, shap_values, base_value, feature_values, 
                               sample_idx, output_dir):
        """
        Create waterfall plot for a specific anomaly.
        
        Shows how each feature contributed to THIS specific anomaly's score.
        
        Args:
            shap_values: SHAP values for all samples [N, features]
            base_value: Expected value (baseline)
            feature_values: Feature values for samples [N, features]
            sample_idx: Index of anomaly to explain
            output_dir: Directory to save plot
        """
        # Create SHAP Explanation object for waterfall
        explanation = shap.Explanation(
            values=shap_values[sample_idx],
            base_values=base_value if np.isscalar(base_value) else base_value[0],
            data=feature_values[sample_idx],
            feature_names=self.feature_names
        )
        
        plt.figure(figsize=(10, 8))
        shap.waterfall_plot(explanation, max_display=15, show=False)
        plt.title(f'Local Explanation: Anomaly #{sample_idx}', fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = Path(output_dir) / f'waterfall_anomaly_{sample_idx}_{timestamp}.png'
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"Saved: {filepath}")
        return filepath
    
    def export_anomaly_details(self, shap_values, test_sequences, 
                               anomaly_indices, output_dir, top_k=3):
        """
        Export detailed CSV of anomalies with top contributing features.
        
        Args:
            shap_values: SHAP values [N, features]
            test_sequences: Test sequences [N, seq_len, features]
            anomaly_indices: Indices of anomalous samples
            output_dir: Directory to save CSV
            top_k: Number of top features to include per anomaly
        
        Returns:
            DataFrame with anomaly details
        """
        records = []
        
        for idx in anomaly_indices:
            # Get SHAP values for this anomaly
            sample_shap = shap_values[idx]
            
            # Top K features by absolute SHAP value
            top_k_idx = np.argsort(np.abs(sample_shap))[-top_k:][::-1]
            
            # Feature values (averaged across time)
            feature_vals = test_sequences[idx].mean(axis=0)
            
            record = {'anomaly_index': idx}
            
            for i, feat_idx in enumerate(top_k_idx, 1):
                record[f'top_{i}_feature'] = self.feature_names[feat_idx]
                record[f'top_{i}_shap_value'] = sample_shap[feat_idx]
                record[f'top_{i}_feature_value'] = feature_vals[feat_idx]
            
            records.append(record)
        
        df = pd.DataFrame(records)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = Path(output_dir) / f'anomaly_details_{timestamp}.csv'
        df.to_csv(filepath, index=False)
        
        print(f"Saved: {filepath}")
        print(f"Exported {len(df)} anomaly details")
        
        return df
    
    def generate_full_report(self, test_sequences, anomaly_flags, 
                            normal_sequences, output_dir='./shap_reports',
                            n_background=100, max_anomalies=50, top_n_features=10):
        """Generate SHAP report with Excel + embedded images."""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        print("="*60)
        print("STARTING SHAP EXPLAINABILITY PIPELINE")
        print("="*60)
        
        anomaly_indices = np.where(anomaly_flags)[0]
        n_anomalies = min(len(anomaly_indices), max_anomalies)
        anomaly_subset = test_sequences[anomaly_indices[:n_anomalies]]
        
        print(f"\nAnalyzing {n_anomalies} anomalies, top {top_n_features} features")
        
        background = self._create_background_data(normal_sequences, n_background)
        shap_values, base_values = self.compute_shap_values(
            anomaly_subset, background, max_samples=n_anomalies
        )
        
        n_display = len(self.feature_names) if top_n_features == 'all' else top_n_features
        feature_ranking = self.global_feature_importance(shap_values, top_n=n_display)
        
        if top_n_features != 'all':
            feature_ranking = feature_ranking.head(top_n_features)
        
        summary = self.generate_executive_summary(
            shap_values, feature_ranking, len(anomaly_indices), 
            len(test_sequences), top_n=top_n_features if top_n_features != 'all' else 10
        )
        
        # Generate plots
        print("\nGenerating visualizations...")
        plot1 = self.plot_global_importance(feature_ranking, output_path, top_n=len(feature_ranking))
        plot2 = self.plot_shap_summary(shap_values, anomaly_subset, output_path, top_n=len(feature_ranking))
        
        top_k = min(3, top_n_features if isinstance(top_n_features, int) else 3)
        details_df = self.export_anomaly_details(
            shap_values, anomaly_subset, range(n_anomalies), output_path, top_k=top_k
        )
        
        # Export to Excel with images
        excel_path = self.export_to_excel_with_images(
            summary, feature_ranking, details_df, output_path, [plot1, plot2]
        )
        
        print(f"\n{'='*60}\nSHAP COMPLETE\nExcel: {excel_path}\n{'='*60}")
        return {'excel_report': excel_path}

    def export_to_excel_with_images(self, summary_text, feature_ranking, 
                                    anomaly_details, output_dir, image_paths):
        """Export to Excel with embedded images, cleanup temp files."""
        from openpyxl.drawing.image import Image as ExcelImage
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = Path(output_dir) / f'shap_analysis_{timestamp}.xlsx'
        
        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            summary_lines = [line.strip() for line in summary_text.strip().split('\n') if line.strip()]
            summary_df = pd.DataFrame({'Executive Summary': summary_lines})
            summary_df.to_excel(writer, sheet_name='Executive Summary', index=False)
            feature_ranking.to_excel(writer, sheet_name='Feature Ranking', index=False)
            anomaly_details.to_excel(writer, sheet_name='Anomaly Details', index=False)
            
            workbook = writer.book
            viz_sheet = workbook.create_sheet('Visualizations')
            
            row = 1
            for img_path in image_paths:
                if Path(img_path).exists():
                    img = ExcelImage(str(img_path))
                    img.width = 600
                    img.height = 480
                    viz_sheet.add_image(img, f'A{row}')
                    row += 30
        
        # Delete all temp files (PNG and CSV)
        for img_path in image_paths:
            try:
                Path(img_path).unlink()
            except:
                pass
        
        # Delete CSV file
        csv_pattern = Path(output_dir) / f'anomaly_details_{timestamp}.csv'
        try:
            csv_pattern.unlink()
        except:
            pass
        
        print(f"\n✓ Excel only: {filepath}")
        return filepath

    def export_to_excel_only(self, summary_text, feature_ranking, anomaly_details, output_dir):
        """Export everything to Excel with embedded images."""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = Path(output_dir) / f'shap_analysis_{timestamp}.xlsx'
        
        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            # Sheet 1: Executive Summary
            summary_lines = [line.strip() for line in summary_text.strip().split('\n') if line.strip()]
            summary_df = pd.DataFrame({'Executive Summary': summary_lines})
            summary_df.to_excel(writer, sheet_name='Executive Summary', index=False)
            
            # Sheet 2: Feature Ranking
            feature_ranking.to_excel(writer, sheet_name='Feature Ranking', index=False)
            
            # Sheet 3: Anomaly Details  
            anomaly_details.to_excel(writer, sheet_name='Anomaly Details', index=False)
        
        print(f"\n✓ Excel report saved: {filepath}")
        return filepath
