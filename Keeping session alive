def flatten_reconciliation_metrics(row):
    # Extract the 'other_keys' dictionary
    other_keys = row.get('other_keys', {})

    # Extract the 'reconciliation_metrics' from 'other_keys'
    reconciliation_metrics = other_keys.get('reconciliation_metrics', {})

    # Remove 'reconciliation_metrics' from 'other_keys' if you don't need it nested anymore
    if 'reconciliation_metrics' in other_keys:
        del other_keys['reconciliation_metrics']

    # Merge 'reconciliation_metrics' into the main dictionary
    updated_row = {**row, **reconciliation_metrics}

    # Optionally update 'other_keys' without 'reconciliation_metrics'
    updated_row['other_keys'] = other_keys

    return updated_row

import pandas as pd

# Sample DataFrame setup - simulate reading from your data
df = pd.DataFrame([{
    'event_id': 'some_id',
    'other_keys': {
        'reconciliation_metrics': {
            'tgt_rec_count': '14',
            'audit_run_id': '123456'
        },
        'some_other_metric': 'value'
    }
}])

# Apply the flattening function to each row in the DataFrame
df = df.apply(flatten_reconciliation_metrics, axis=1)

# Now, df should have 'reconciliation_metrics' flattened into each row's dictionary
print(df.head())

======================
def safe_json_loads(x):
    try:
        return json.loads(x)
    except ValueError:
        return x  # Return the input as-is if it's not a valid JSON string

df['other_keys'] = df['other_keys'].apply(safe_json_loads)


sample_data = {
    'other_keys': {  # This represents the actual structure as it might appear in your DataFrame
        'reconciliation_metrics': [
            {
                'PROD': {
                    'details': {
                        'audit_run_id': 'PROD123',
                        'tgt_rec_count': '100'
                    }
                },
                'COB': {
                    'details': {
                        'audit_run_id': 'COB456',
                        'tgt_rec_count': '200'
                    }
                }
            }
        ]
    }
}
def extract_values(data, key):
    """Recursively search for values of a specific key in nested dict/list."""
    if isinstance(data, dict):
        for k, v in data.items():
            if k == key:
                yield v
            elif isinstance(v, (dict, list)):
                yield from extract_values(v, key)
    elif isinstance(data, list):
        for item in data:
            yield from extract_values(item, key)

# Extract 'audit_run_id' from the provided sample data
results = list(extract_values(sample_data['other_keys'], 'audit_run_id'))  # Accessing nested under 'other_keys'
print(results)  # Expected output would be the audit_run_ids based on the actual structure

# Extract 'tgt_rec_count' similarly
tgt_counts = list(extract_values(sample_data['other_keys'], 'tgt_rec_count'))
print(tgt_counts)  # Expected to print the tgt_rec_counts
import pandas as pd

# Mock DataFrame
df = pd.DataFrame({
    'other_keys': [sample_data['other_keys']]  # Assuming each row contains data like our sample
})

# Applying the function to extract 'audit_run_id' and 'tgt_rec_count'
df['audit_run_ids'] = df['other_keys'].apply(lambda x: list(extract_values(x, 'audit_run_id')))
df['tgt_rec_counts'] = df['other_keys'].apply(lambda x: list(extract_values(x, 'tgt_rec_count')))

print(df[['audit_run_ids', 'tgt_rec_counts']])



=====

# Create a regular expression for case-insensitive matching of job_status
regex_job_status = re.compile('^Success$', re.IGNORECASE)

# Create regular expressions for case-insensitive matching of job types
job_types = ["ingestion", "std", "ReconProfile"]
regex_job_types = [re.compile(f'^{job_type}$', re.IGNORECASE) for job_type in job_types]

# Define the query using regular expressions
query = {
    "job_status": regex_job_status,
    "job_type": {"$in": regex_job_types},
    "some_timestamp_field": {"$gte": int(insert_timestamp)}
}
# Perform the query using the conditions
results = main_collection.find(query)
======

# Access the 'recon_profile_collection'
recon_profile_collection = db["recon_profile_collection"]

# Fetch the most recent timestamp
latest_entry = recon_profile_collection.find_one({}, sort=[("insert_timestamp", -1)])
insert_timestamp = latest_entry['insert_timestamp']['$date']['$numberLong']
====

import json

# Path to your JSON file
file_path = 'your_data.json'

data = []
with open(file_path, 'r') as file:
    for line in file:
        data.append(json.loads(line))  # Load each line as a separate JSON object

print(data)


=====

# Convert all values in search_criteria to lowercase
search_criteria_lower = [{k: v.lower() for k, v in criteria.items()} for criteria in search_criteria]

# Filter the list of dictionaries based on the presence of any of the search criteria
filtered_data = [d for d in data if any(all(d.get(key, '').lower() == value for key, value in criteria.items()) for criteria in search_criteria_lower)]
===============

import pandas as pd
import json

# Path to your JSON file
file_path = 'your_data.json'

# Load the JSON data into a Python list of dictionaries
with open(file_path, 'r') as file:
    data = json.load(file)  # This loads the whole JSON array into a list of dictionaries

# Define the dictionary containing keys and values to search for
search_dict = {
    'key1': 'value1',
    'key2': 'value2',
    # Add more key-value pairs as needed
}

# Convert values in the search dictionary to lowercase for case-insensitive comparison
search_dict_lower = {k: v.lower() for k, v in search_dict.items()}

# Filter the list of dictionaries based on the values in the nested dictionary
filtered_data = [d for d in data if isinstance(d.get('other_keys'), dict) and all(d.get('other_keys').get(key, '').lower() == value for key, value in search_dict_lower.items())]

# Filter the remaining dictionaries based on the keys and values in the main dictionary
filtered_data = [d for d in filtered_data if all(d.get(key, '').lower() == value for key, value in search_dict_lower.items())]

# Create a DataFrame from the filtered list of dictionaries
df = pd.DataFrame(filtered_data)

# Display the DataFrame
print(df)
====

jobdetails_Collection_Filtered_dict = [d for d in jobdetails_Collection_Filtered_dict if isinstance(d.get('other_keys'), dict) and all(d.get('other_keys').get(key, "").lower() == value for key, value in collection_child_Search_criteria)]
========

import pandas as pd

# Assuming your list of dictionaries is stored in jobdetails_Collection_Filtered_dict

# Define the search criteria
search_criteria = {
    'databaseName': 'your_database_name',
    'TableName': 'your_table_name',
    'job_status': 'Success',
    'exec_env': 'your_exec_env'
}

# Filter the list of dictionaries based on the search criteria
filtered_data = [d for d in jobdetails_Collection_Filtered_dict if all(d.get(key) == value for key, value in search_criteria.items())]

# Create a DataFrame from the filtered list of dictionaries
df = pd.DataFrame(filtered_data)

# Display the DataFrame
print(df)
=======

import pandas as pd

# Assuming your list of dictionaries is stored in jobdetails_Collection_Filtered_dict

# Define the search criteria, directly including paths for nested dictionaries
search_criteria = {
    'other_keys.databaseName': 'your_database_name',
    'other_keys.TableName': 'your_table_name',
    'job_status': 'Success',
    'exec_env': 'PROD'
}

# Filter the list of dictionaries based on the search criteria
filtered_data = [d for d in jobdetails_Collection_Filtered_dict if all(
    d.get(key.split('.')[0]).get(key.split('.')[1], {}) == value if '.' in key else d.get(key) == value
    for key, value in search_criteria.items())]

# Create a DataFrame from the filtered list of dictionaries
df = pd.DataFrame(filtered_data)

# Display the DataFrame
print(df)
====

f1['audit_run_id'] = df1['other_keys'].apply(lambda x: x.get('audit_run_id', None))
df1['tgt_record_count'] = df1['other_keys'].apply(lambda x: x.get('tgt_record_count', None))

# Do the same for df2
df2['audit_run_id'] = df2['other_keys'].apply(lambda x: x.get('audit_run_id', None))
df2['tgt_record_count'] = df2['other_keys'].apply(lambda x: x.get('tgt_record_count', None))

# Merge DataFrames based on 'audit_run_id'
merged_df = pd.merge(df1, df2, on='audit_run_id', suffixes=('_df1', '_df2'))

# Display the merged DataFrame
print(merged_df)
# Check if 'tgt_record_count' matches between the two DataFrames
merged_df['tgt_record_count_match'] = merged_df['tgt_record_count_df1'] == merged_df['tgt_record_count_df2']

# Display the result
print(merged_df[['audit_run_id', 'tgt_record_count_df1', 'tgt_record_count_df2', 'tgt_record_count_match']])
====================
def get_nested_value(d, key_path):
    """Safely get a nested value from a dictionary."""
    current_value = d
    for key in key_path.split('.'):
        if isinstance(current_value, dict) and key in current_value:
            current_value = current_value[key]
        else:
            return None
    return current_value

# Define search criteria
search_criteria = {
    'job_status': 'Success',  # Top-level key
    'other_keys.ingestion_type': 'dual'  # Nested key
}

# Filter the list of dictionaries based on nested criteria
filtered_dictionaries = [
    d for d in jobdetails_Collection_Filtered_dict
    if all(get_nested_value(d, key) == value for key, value in search_criteria.items())
]

# Output the filtered dictionaries
print(filtered_dictionaries)


========================
filter dict ingestion type
===========================

# Example list of dictionaries (constructed based on the image's structure)
jobdetails_Collection_Filtered_dict = [
    {'job_status': 'Success', 'ingestion_type': 'dual', 'details': {'audit_run_id': 123}},
    {'job_status': 'Success', 'ingestion_type': 'single', 'details': {'audit_run_id': 456}},
    {'job_status': 'Failure', 'ingestion_type': 'dual', 'details': {'audit_run_id': 789}}
]

# Define the search criteria for top-level keys
search_criteria = {'job_status': 'Success', 'ingestion_type': 'dual'}

# Filtered list of dictionaries based on criteria
filtered_dictionaries = [
    d for d in jobdetails_Collection_Filtered_dict
    if all(d.get(key) == value for key, value in search_criteria.items())
]

# Print the filtered dictionaries
for entry in filtered_dictionaries:
    print(entry)
==========
NESTED 
======

def get_nested_value(d, key_path):
    keys = key_path.split('.')
    current = d
    for key in keys:
        if isinstance(current, dict) and key in current:
            current = current[key]
        else:
            return None

search_criteria = {
    'job_status': 'Success',
    'ingestion_type': 'dual',
    'details.audit_run_id': 123
}

jobdetails_Collection_Filtered_dict = [
    {'job_status': 'Success', 'ingestion_type': 'dual', 'details': {'audit_run_id': 123}},
    {'job_status': 'Success', 'ingestion_type': 'single', 'details': {'audit_run_id': 456}},
    {'job_status': 'Failure', 'ingestion_type': 'dual', 'details': {'audit_run_id': 789}}
]

filtered_dictionaries = [
    d for d in jobdetails_Collection_Filtered_dict
    if all(get_nested_value(d, key) == value for key, value in search_criteria.items())
]

for entry in filtered_dictionaries:
    print(entry)

========
DF operations 
=======

import pandas as pd

# Assuming 'df' is the DataFrame and 'Reconciliation metrics' is the column containing nested JSON
# Normalize the nested JSON data into separate columns for each part of 'Reconciliation metrics'
df_expanded = df['Reconciliation metrics'].apply(pd.Series)

# Expand PROD and COB data into their own DataFrame columns
df_prod = df_expanded['PROD'].apply(lambda x: x[0] if x else {}).apply(pd.Series)
df_cob = df_expanded['COB'].apply(lambda x: x[0] if x else {}).apply(pd.Series)

# Provide default values for hash_value and tgt_rec_count if missing
df_prod['hash_value'] = df_prod['hash_value'].fillna('NA')
df_cob['hash_value'] = df_cob['hash_value'].fillna('NA')
df_prod['tgt_rec_count'] = df_prod['tgt_rec_count'].fillna(0)
df_cob['tgt_rec_count'] = df_cob['tgt_rec_count'].fillna(0)

# Merge these new DataFrames back to the original DataFrame with appropriate prefixes
df_final = pd.concat([df, df_prod.add_prefix('PROD_'), df_cob.add_prefix('COB_')], axis=1)

# Compare hash_value and tgt_rec_count between PROD and COB
df_final['hash_value_match'] = df_final['PROD_hash_value'] == df_final['COB_hash_value']
df_final['tgt_rec_count_match'] = df_final['PROD_tgt_rec_count'] == df_final['COB_tgt_rec_count']

# Optionally, fill or clean further if necessary
df_final.fillna('NA', inplace=True)  # Replace any remaining NaN values with 'NA'

# Print or output the DataFrame to review the results
print(df_final[['PROD_hash_value', 'COB_hash_value', 'hash_value_match', 'PROD_tgt_rec_count', 'COB_tgt_rec_count', 'tgt_rec_count_match']])
=================

import pandas as pd

# Function to recursively extract values from nested dictionaries
def extract_values(data, key):
    """Recursively search for values of a specific key in nested dict/list."""
    if isinstance(data, dict):
        for k, v in data.items():
            if k == key:
                yield v
            elif isinstance(v, (dict, list)):
                yield from extract_values(v, key)
    elif isinstance(data, list):
        for item in data:
            yield from extract_values(item, key)

# Assuming df['other_keys'] contains the nested dictionaries with 'reconciliation_metrics'
# First, ensure that 'other_keys' is a dictionary (if it's a stringified JSON, convert it)
df['other_keys'] = df['other_keys'].apply(lambda x: json.loads(x) if isinstance(x, str) else x)

# Apply the extraction function to the 'other_keys' column, targeting the nested 'reconciliation_metrics'
df['audit_run_ids'] = df['other_keys'].apply(lambda x: list(extract_values(x.get('reconciliation_metrics', {}), 'audit_run_id')))

# Show results
print(df['audit_run_ids'])
===

sample 
sample_data = {
    'reconciliation_metrics': {
        'details': {
            'audit_run_id': ['123', '456']
        }
    }
}

# Test the function with sample data
print(list(extract_values(sample_data, 'audit_run_id')))  # Expected to print ['123', '456']


