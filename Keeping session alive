import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions.count

val spark: SparkSession = SparkSession.builder()
  .appName("Check Duplicate Columns")
  .getOrCreate()

// Sample DataFrame and column arrays
val df = spark.createDataFrame(Seq(
  ("value1", "value2", "value3"),
  ("value4", "value5", "value6"),
  ("value1", "value7", "value8"),
  ("value9", "value2", "value3")
)).toDF("ColumnA", "ColumnB", "ColumnC")

val array1: Array[String] = Array("ColumnA", "ColumnB", "ColumnC")
val array2: Array[String] = Array("ColumnB") // Example of columns to exclude

// Calculate the difference between the two arrays to determine which columns to check for duplicates
val resultArray = array1.diff(array2)

// Function to check for duplicate values in each specified column and display them
def checkAndDisplayDuplicates(df: org.apache.spark.sql.DataFrame, columns: Array[String]): Unit = {
  columns.foreach { colName =>
    val duplicates = df.groupBy(colName)
      .agg(count(colName).alias("count"))
      .filter($"count" > 1)
      .drop("count")
    
    println(s"Duplicates in $colName:")
    duplicates.show()
  }
}

// Calling the function with the DataFrame and the resultArray
checkAndDisplayDuplicates(df, resultArray)

spark.stop()
