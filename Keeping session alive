// In your benchmarkMD5Methods function, add this section for DigestUtils
logger.info("Testing Apache Commons DigestUtils.md5Hex method")
println("Testing Apache Commons DigestUtils.md5Hex method")

val startTimeDigestUtils = System.nanoTime()
try {
  val md5Checksum = org.apache.commons.codec.digest.DigestUtils.md5Hex(fs.open(new Path(hdfsFilePath)))
  val endTimeDigestUtils = System.nanoTime()
  val durationSecondsDigestUtils = (endTimeDigestUtils - startTimeDigestUtils) / 1e9
  
  // Calculate throughput
  val throughputMBps = (fileSize / 1024.0 / 1024.0) / durationSecondsDigestUtils
  
  logger.info(s"DigestUtils MD5 checksum: $md5Checksum")
  logger.info(f"DigestUtils time taken: $durationSecondsDigestUtils%.3f seconds")
  logger.info(f"DigestUtils throughput: $throughputMBps%.2f MB/second")
  
  // Add to results map
  results("DigestUtils") = (md5Checksum, durationSecondsDigestUtils)
} catch {
  case e: Exception =>
    logger.error(s"Error with DigestUtils method: ${e.getMessage}")
    logger.error("This is expected for large files as DigestUtils loads the entire file into memory")
}

// For an HDFS file
def calculateMD5WithGuavaHDFS(hdfsFilePath: String, fs: org.apache.hadoop.fs.FileSystem): String = {
  val path = new Path(hdfsFilePath)
  
  // Create a ByteSource from HDFS InputStream
  val byteSource = new ByteSource() {
    override def openStream(): java.io.InputStream = {
      fs.open(path)
    }
  }
  
  byteSource.hash(Hashing.md5()).toString
}
// Add this to your benchmarking method
try {
  logger.info("Testing Google Guava Hashing for HDFS")
  println("Testing Google Guava Hashing for HDFS")
  
  val startTimeGuava = System.nanoTime()
  val md5HashGuava = calculateMD5WithGuavaHDFS(hdfsFilePath, fs)
  val endTimeGuava = System.nanoTime()
  val durationGuava = (endTimeGuava - startTimeGuava) / 1e9
  
  // Calculate throughput
  val throughputGuava = (fileSize / 1024.0 / 1024.0) / durationGuava
  
  logger.info(s"Guava MD5 Hash: $md5HashGuava")
  logger.info(f"Guava Time: $durationGuava%.3f seconds")
  logger.info(f"Guava Throughput: $throughputGuava%.2f MB/second")
  
  // Add to results map
  results("Guava") = (md5HashGuava, durationGuava)
} catch {
  case e: Exception =>
    logger.error(s"Error with Guava method: ${e.getMessage}", e)
}
