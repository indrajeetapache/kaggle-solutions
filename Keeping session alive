
import org.apache.spark.sql.SparkSession

def getPartitionColumns(spark: SparkSession, tableName: String): Seq[String] = {
  // Execute 'SHOW CREATE TABLE' command to get the table's DDL
  val createTableDDL = spark.sql(s"SHOW CREATE TABLE $tableName").collect().map(_.getString(0)).mkString("\n")

  // Extract the partition column details from the DDL
  val partitionPattern = "(?i)PARTITIONED BY\\s*\\(([^)]+)\\)".r
  partitionPattern.findFirstMatchIn(createTableDDL) match {
    case Some(matched) => 
      val partitionPart = matched.group(1)
      partitionPart.split(",").map(_.trim.split("\\s+")(0)) // Extracting column names
    case None => 
      Array[String]() // Return an empty array if the table is not partitioned
  }
}

// Usage
val spark: SparkSession = // your SparkSession
val tableName = "your_table_name"
val partitionColumns = getPartitionColumns(spark, tableName)
partitionColumns.foreach(println)


====
import org.apache.spark.sql.DataFrame
import scala.util.matching.Regex

def isString(value: String): Boolean = {
    val stringPattern: Regex = "^[A-Za-z]+$".r
    stringPattern.findFirstIn(value).isDefined
}

def matchesDateFormat(value: String, formats: List[String]): Boolean = {
    // Function to check if a value matches any of the provided date formats
    def checkFormat(format: String): Boolean = {
        format match {
            case "yyyymmdd" => value.matches("\\d{8}")
            case "yyyymm"   => value.matches("\\d{6}")
            case "yyyy"     => value.matches("\\d{4}")
            case _          => false
        }
    }
    formats.exists(checkFormat)
}

def validatePartitionColumns(df: DataFrame, partitionColumns: Array[String]): Array[String] = {
    partitionColumns.filter { col =>
        val sampleValue = df.select(col).first().getString(0).filter(_.isDigit)
        if (col == "map_load_Date") {
            // Check various date formats for the 'map_load_Date' column
            !matchesDateFormat(sampleValue, List("yyyymmdd", "yyyymm", "yyyy"))
        } else {
            // For other columns, check if they are strings
            !isString(sampleValue)
        }
    }
}

// Usage
val df1: DataFrame = // Your DataFrame
val partitionColumns = Array("map_load_Date", "file_name")
val validatedColumns = validatePartitionColumns(df1, partitionColumns)

// Example to print validated columns
validatedColumns.foreach(println)

}

