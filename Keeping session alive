import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions.count

val spark: SparkSession = SparkSession.builder()
  .appName("Check Duplicate Columns")
  .getOrCreate()

// Assuming df is your DataFrame
// Assuming array1 and array2 are defined as before
val resultArray = array1.diff(array2)

// Adjusted function
def checkAndDisplayDuplicates(df: org.apache.spark.sql.DataFrame, columns: Array[String]): Unit = {
  columns.foreach { colName =>
    val duplicates = df.groupBy(colName)
      .agg(count(colName).alias("count"))
      .filter($"count" > 1)
      .drop("count")
    
    // Check if duplicates DataFrame is non-empty before showing
    if (duplicates.count() > 0) {
      println(s"Duplicates in $colName:")
      duplicates.show()
    }
  }
}

// Call the function
checkAndDisplayDuplicates(df, resultArray)

spark.stop()
