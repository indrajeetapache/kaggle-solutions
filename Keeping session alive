"""
Enhanced SHAP Explainability for LSTM Anomaly Detection
Complete implementation with Phase 1 helpers and Phase 2 DataFrame builders

New capabilities:
- Historical statistics calculation
- Anomaly-to-original data mapping
- Business description generation
- Structured DataFrame outputs for all report tabs
- Configurable parameters for flexibility
"""

import numpy as np
import pandas as pd
import shap
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime
import torch
import warnings
from io import BytesIO
warnings.filterwarnings('ignore')

class SHAPAnomalyExplainer:
    """
    SHAP-based explainability for LSTM autoencoder anomaly detection.
    Generates structured Excel reports with global and local explanations.
    """

    def __init__(self, model, scaler, feature_names, seq_length, device='cpu'):
        """
        Initialize explainer with trained model.

        Args:
            model: Trained LSTMAutoencoder (PyTorch)
            scaler: Fitted StandardScaler from training
            feature_names: List of feature column names
            seq_length: Sequence length used in training
            device: torch device ('cpu' or 'cuda')
        """
        self.model = model
        self.scaler = scaler
        self.feature_names = feature_names
        self.seq_length = seq_length
        self.device = device
        self.model.eval()

        print(f"SHAPAnomalyExplainer initialized:")
        print(f"  - Features: {len(feature_names)}")
        print(f"  - Sequence length: {seq_length}")
        print(f"  - Device: {device}")

    # ==================== PHASE 1: HELPER FUNCTIONS ====================
    
    def _calculate_historical_stats_from_df(self, original_df, feature_names_subset, threshold=95):
        """
        Calculate historical statistics from RAW original DataFrame.
        This ensures stats match the original unscaled data distribution.
        
        Args:
            original_df: Original unscaled DataFrame
            feature_names_subset: List of feature names to compute
            threshold: Percentile threshold (e.g., 95, 98)
            
        Returns:
            dict: {feature_name: {'mean': X, 'std': Y, 'p_lower': Z, 'p_upper': W, ...}}
        """
        print(f"\nCalculating historical stats from RAW data (threshold={threshold}%)...")
        
        p_lower = (100 - threshold) / 2
        p_upper = 100 - p_lower
        
        historical_stats = {}
        
        for feature_name in feature_names_subset:
            if feature_name not in original_df.columns:
                continue
                
            feature_values = original_df[feature_name].values
            
            stats = {
                'mean': float(np.mean(feature_values)),
                'std': float(np.std(feature_values)),
                'min': float(np.min(feature_values)),
                'max': float(np.max(feature_values)),
                'p_lower': float(np.percentile(feature_values, p_lower)),
                'p25': float(np.percentile(feature_values, 25)),
                'p50': float(np.percentile(feature_values, 50)),
                'p75': float(np.percentile(feature_values, 75)),
                'p_upper': float(np.percentile(feature_values, p_upper)),
                'threshold': threshold
            }
            
            historical_stats[feature_name] = stats
        
        print(f"  Computed RAW stats for {len(historical_stats)} features (P{p_lower:.1f}-P{p_upper:.1f})")
        return historical_stats
    
    def _calculate_historical_stats(self, normal_sequences, feature_subset=None, threshold=95):
        """
        Calculate historical statistics from normal training sequences.
        Computes mean, std, min, max, and percentiles for each feature.
        
        Args:
            normal_sequences: Array (n_samples, seq_length, n_features)
            feature_subset: List of feature indices (None = all features)
            threshold: Percentile threshold (e.g., 95 for 95th percentile)
            
        Returns:
            dict: {feature_name: {'mean': X, 'std': Y, 'p_lower': Z, 'p_upper': W, ...}}
        """
        print(f"\nCalculating historical statistics (threshold={threshold}%) from normal sequences...")
        
        if feature_subset is None:
            feature_subset = range(len(self.feature_names))
        
        # Calculate complementary percentiles
        p_lower = (100 - threshold) / 2
        p_upper = 100 - p_lower
        
        historical_stats = {}
        
        for feat_idx in feature_subset:
            feature_name = self.feature_names[feat_idx]
            feature_values = normal_sequences[:, :, feat_idx].flatten()
            
            stats = {
                'mean': float(np.mean(feature_values)),
                'std': float(np.std(feature_values)),
                'min': float(np.min(feature_values)),
                'max': float(np.max(feature_values)),
                'p_lower': float(np.percentile(feature_values, p_lower)),
                'p25': float(np.percentile(feature_values, 25)),
                'p50': float(np.percentile(feature_values, 50)),
                'p75': float(np.percentile(feature_values, 75)),
                'p_upper': float(np.percentile(feature_values, p_upper)),
                'threshold': threshold
            }
            
            historical_stats[feature_name] = stats
        
        print(f"  Computed stats for {len(historical_stats)} features (P{p_lower:.1f}-P{p_upper:.1f})")
        return historical_stats
    
    def _map_anomaly_to_original_data(self, anomaly_indices, original_df, date_col='load_date'):
        """
        Map detected anomaly indices back to original DataFrame rows.
        Extracts timestamps and creates pipeline IDs.
        
        Args:
            anomaly_indices: Array of anomaly positions in test sequences
            original_df: Original DataFrame used for LSTM
            date_col: Name of date/timestamp column
            
        Returns:
            DataFrame: ['anomaly_index', 'pipeline_id', 'timestamp', 'original_row_idx']
        """
        print(f"\nMapping {len(anomaly_indices)} anomalies to original data...")
        
        mapping_records = []
        
        for idx, anomaly_idx in enumerate(anomaly_indices):
            original_row = anomaly_idx + self.seq_length - 1
            
            if original_row < len(original_df):
                timestamp = original_df.iloc[original_row][date_col]
            else:
                timestamp = pd.NaT
            
            timestamp_str = pd.to_datetime(timestamp).strftime('%Y%m%d_%H%M%S') \
                           if pd.notna(timestamp) else 'UNKNOWN'
            pipeline_id = f"ANOM_{timestamp_str}_{idx:04d}"
            
            mapping_records.append({
                'anomaly_index': anomaly_idx,
                'pipeline_id': pipeline_id,
                'timestamp': timestamp,
                'original_row_idx': original_row
            })
        
        mapping_df = pd.DataFrame(mapping_records)
        print(f"  Successfully mapped {len(mapping_df)} anomalies")
        return mapping_df
    
    def _generate_business_description(self, z_score, feature_value, normal_range, 
                                        feature_name, z_thresholds=None):
        """
        Generate human-readable description of anomaly severity.
        Uses Z-score and feature context for business-friendly text.
        
        Args:
            z_score: Calculated Z-score
            feature_value: Actual feature value
            normal_range: String representation (e.g., "10-50")
            feature_name: Feature name
            z_thresholds: Dict with severity thresholds
            
        Returns:
            str: Business description
        """
        if z_thresholds is None:
            z_thresholds = {
                'extreme_high': 3.0,
                'extreme_low': -3.0,
                'significant_high': 2.0,
                'significant_low': -2.0,
                'moderate_high': 1.5,
                'moderate_low': -1.5
            }
        
        if z_score >= z_thresholds['extreme_high']:
            severity = "Extremely higher"
        elif z_score <= z_thresholds['extreme_low']:
            severity = "Extremely lower"
        elif z_score >= z_thresholds['significant_high']:
            severity = "Significantly higher"
        elif z_score <= z_thresholds['significant_low']:
            severity = "Significantly lower"
        elif z_score >= z_thresholds['moderate_high']:
            severity = "Moderately higher"
        elif z_score <= z_thresholds['moderate_low']:
            severity = "Moderately lower"
        else:
            severity = "Slightly different"
        
        description = f"{severity} than normal (Z-score: {z_score:.2f}). "
        description += f"Value: {feature_value:.2f}, Normal range: {normal_range}"
        
        return description
    
    def _get_dq_dimension(self, feature_name):
        """Map feature name to Data Quality dimension based on keywords."""
        DQ_KEYWORDS = {
            'Completeness': ['completeness', 'missing', 'null', 'isnotnull'],
            'Accuracy': ['accuracy', 'entropy', 'zscore', 'outlier', 'anomaly', 
                        'mean', 'sum', 'count'],
            'Consistency': ['consistency', 'standarddeviation', 'variance', 'correlation'],
            'Validity': ['validity', 'minimum', 'maximum', 'datatype', 'pattern', 'regex'],
            'Uniqueness': ['uniqueness', 'countdistinct', 'distinctness', 'duplicate'],
            'Timeliness': ['timeliness', 'freshness', 'lag', 'delay', 'timestamp']
        }
        
        feature_lower = feature_name.lower()
        for dimension, keywords in DQ_KEYWORDS.items():
            if any(kw in feature_lower for kw in keywords):
                return dimension
        return 'Unknown'
    
    def _get_severity_from_dq_dimension(self, dq_dimension):
        """Map DQ dimension to severity level."""
        criticality_map = {
            'Accuracy': 'Critical',
            'Completeness': 'Critical',
            'Consistency': 'Critical',
            'Timeliness': 'Warning',
            'Validity': 'Warning',
            'Uniqueness': 'Warning',
            'Unknown': 'Unknown'
        }
        return criticality_map.get(dq_dimension, 'Unknown')
    
    def _filter_anomalies_by_date(self, anomaly_indices, original_df, date_col, report_dates):
        """
        Filter anomaly indices to only include specified dates.
        
        Args:
            anomaly_indices: Array of anomaly positions
            original_df: Original DataFrame with date column
            date_col: Name of date column
            report_dates: Single date string, list of dates, or None
            
        Returns:
            np.array: Filtered anomaly indices
        """
        # Convert report_dates to list if single date
        if isinstance(report_dates, str):
            report_dates = [report_dates]
        
        # Convert to datetime for comparison
        report_dates = [pd.to_datetime(d).date() for d in report_dates]
        
        filtered_indices = []
        
        for anomaly_idx in anomaly_indices:
            # Calculate original row index (last timestep of sequence)
            original_row = anomaly_idx + self.seq_length - 1
            
            if original_row < len(original_df):
                row_date = pd.to_datetime(original_df.iloc[original_row][date_col]).date()
                
                if row_date in report_dates:
                    filtered_indices.append(anomaly_idx)
        
        return np.array(filtered_indices)

    # ==================== PHASE 2: DATAFRAME BUILDERS ====================
    
    def build_summary_dataframe(self, anomaly_count, total_samples, date_range,
                                 columns_analyzed, columns_with_anomalies,
                                 top_features, threshold, anomalies_df=None):
        """
        Build structured summary DataFrame for Tab 1.
        
        Args:
            anomaly_count: Total anomalies detected
            total_samples: Total samples analyzed
            date_range: Tuple (start_date, end_date)
            columns_analyzed: Number of features
            columns_with_anomalies: Number of features with anomalies
            top_features: List of top feature names
            threshold: Anomaly detection threshold
            anomalies_df: Anomalies DataFrame to calculate real severity breakdown
            
        Returns:
            DataFrame: Summary metrics
        """
        print("\nBuilding summary DataFrame...")
        
        # Calculate REAL severity breakdown from anomalies_df
        if anomalies_df is not None and 'Severity' in anomalies_df.columns:
            severity_counts = anomalies_df['Severity'].value_counts()
            critical_anomalies = severity_counts.get('Critical', 0)
            high_anomalies = severity_counts.get('Warning', 0)
            low_anomalies = severity_counts.get('Unknown', 0)
        else:
            # Fallback if anomalies_df not provided
            critical_anomalies = 0
            high_anomalies = 0
            low_anomalies = anomaly_count
        
        date_range_str = f"{date_range[0]} to {date_range[1]}"
        top_features_str = ", ".join(top_features)
        
        summary_df = pd.DataFrame({
            'Metric': [
                'Total Anomalies Detected',
                'Critical Anomalies',
                'High Anomalies',
                'Low Anomalies',
                'Date Range',
                'Columns Analyzed',
                'Columns w/ Anomalies',
                'Top 3 Anomalous Features',
                'Threshold'
            ],
            'Value': [
                anomaly_count,
                critical_anomalies,
                high_anomalies,
                low_anomalies,
                date_range_str,
                columns_analyzed,
                columns_with_anomalies,
                top_features_str,
                threshold
            ]
        })
        
        print(f"  Summary created with {len(summary_df)} metrics")
        return summary_df
    
    def build_anomalies_dataframe(self, anomaly_subset, shap_values, anomaly_indices,
                                   original_df, historical_stats, date_col='load_date',
                                   top_k=3, z_thresholds=None):
        """
        Build detailed anomalies DataFrame for Tab 2.
        
        Args:
            anomaly_subset: Anomaly sequences (n_anomalies, seq_length, n_features)
            shap_values: SHAP values (n_anomalies, n_features)
            anomaly_indices: Original indices of anomalies
            original_df: Original DataFrame
            historical_stats: Dict from _calculate_historical_stats()
            date_col: Date column name
            top_k: Number of top features per anomaly
            z_thresholds: Custom Z-score thresholds
            
        Returns:
            DataFrame: Detailed anomaly records
        """
        print(f"\nBuilding anomalies DataFrame for {len(anomaly_subset)} anomalies...")
        
        # Map anomalies to original data
        mapping_df = self._map_anomaly_to_original_data(anomaly_indices, original_df, date_col)
        
        records = []
        
        for idx in range(len(anomaly_subset)):
            sample_shap = shap_values[idx]
            top_k_idx = np.argsort(np.abs(sample_shap))[-top_k:][::-1]
            
            # Get raw values from original DataFrame
            original_row_idx = mapping_df.iloc[idx]['original_row_idx']
            
            pipeline_id = mapping_df.iloc[idx]['pipeline_id']
            timestamp = mapping_df.iloc[idx]['timestamp']
            
            for rank, feat_idx in enumerate(top_k_idx, 1):
                feature_name = self.feature_names[feat_idx]
                
                # Extract RAW value from original DataFrame
                raw_feature_value = original_df.iloc[original_row_idx][feature_name]
                
                shap_value = sample_shap[feat_idx]
                
                # Get historical stats (computed from raw data)
                stats = historical_stats.get(feature_name, {})
                hist_mean = stats.get('mean', 0)
                hist_std = stats.get('std', 1)
                hist_min = stats.get('min', 0)
                hist_max = stats.get('max', 0)
                hist_p_lower = stats.get('p_lower', 0)
                hist_p_upper = stats.get('p_upper', 0)
                
                # Calculate metrics using RAW values
                z_score = (raw_feature_value - hist_mean) / hist_std if hist_std > 0 else 0
                expected_value = hist_mean
                difference = raw_feature_value - expected_value
                deviation_pct = (difference / expected_value * 100) if expected_value != 0 else 0
                normal_range = f"{hist_p_lower:.2f}-{hist_p_upper:.2f}"
                
                # Get scaled value for reference
                scaled_feature_value = anomaly_subset[idx].mean(axis=0)[feat_idx]
                
                # DQ dimension and severity
                dq_dimension = self._get_dq_dimension(feature_name)
                severity = self._get_severity_from_dq_dimension(dq_dimension)
                
                # Business description using RAW values
                description = self._generate_business_description(
                    z_score, raw_feature_value, normal_range, feature_name, z_thresholds
                )
                
                record = {
                    'pipeline_id': pipeline_id,
                    'Timestamp': timestamp,
                    'column_name': feature_name,
                    'Feature_Name': feature_name,
                    'dq_dimension': dq_dimension,
                    'Severity': severity,
                    'Anomaly_Score': abs(shap_value),
                    'Raw_Value': raw_feature_value,
                    'Scaled_Value': scaled_feature_value,
                    'Expected_Value': expected_value,
                    'Difference': difference,
                    'Deviation_%': deviation_pct,
                    'Historical_Mean': hist_mean,
                    'Historical_Std': hist_std,
                    'Historical_Min': hist_min,
                    'Historical_Max': hist_max,
                    'Normal_Range': normal_range,
                    'Z-Score': z_score,
                    'Description': description
                }
                
                records.append(record)
        
        anomalies_df = pd.DataFrame(records)
        print(f"  Created {len(anomalies_df)} anomaly detail records")
        return anomalies_df
    
    def build_feature_contribution_dataframe(self, anomaly_subset, shap_values,
                                              anomaly_indices, original_df,
                                              historical_stats, date_col='load_date',
                                              top_k=3, z_thresholds=None):
        """
        Build feature contribution DataFrame for Tab 3.
        
        Args:
            anomaly_subset: Anomaly sequences
            shap_values: SHAP values
            anomaly_indices: Original indices
            original_df: Original DataFrame
            historical_stats: Historical statistics dict
            date_col: Date column name
            top_k: Number of top features per anomaly
            z_thresholds: Custom Z-score thresholds
            
        Returns:
            DataFrame: Feature contribution details
        """
        print(f"\nBuilding feature contribution DataFrame...")
        
        mapping_df = self._map_anomaly_to_original_data(anomaly_indices, original_df, date_col)
        
        records = []
        
        for idx in range(len(anomaly_subset)):
            sample_shap = shap_values[idx]
            top_k_idx = np.argsort(np.abs(sample_shap))[-top_k:][::-1]
            
            # Get raw values from original DataFrame
            original_row_idx = mapping_df.iloc[idx]['original_row_idx']
            pipeline_id = mapping_df.iloc[idx]['pipeline_id']
            
            for rank, feat_idx in enumerate(top_k_idx, 1):
                feature_name = self.feature_names[feat_idx]
                
                # Extract RAW value from original DataFrame
                raw_feature_value = original_df.iloc[original_row_idx][feature_name]
                scaled_feature_value = anomaly_subset[idx].mean(axis=0)[feat_idx]
                
                contribution_score = abs(sample_shap[feat_idx])
                
                stats = historical_stats.get(feature_name, {})
                hist_mean = stats.get('mean', 0)
                hist_std = stats.get('std', 1)
                hist_p_lower = stats.get('p_lower', 0)
                hist_p_upper = stats.get('p_upper', 0)
                
                z_score = (raw_feature_value - hist_mean) / hist_std if hist_std > 0 else 0
                normal_range = f"{hist_p_lower:.2f}-{hist_p_upper:.2f}"
                
                description = self._generate_business_description(
                    z_score, raw_feature_value, normal_range, feature_name, z_thresholds
                )
                
                record = {
                    'pipeline_id': pipeline_id,
                    'Feature_Name': feature_name,
                    'Raw_Value': raw_feature_value,
                    'Scaled_Value': scaled_feature_value,
                    'Normal_Range': normal_range,
                    'Contribution_Score': contribution_score,
                    'Business_Description': description,
                    'Contribution_Rank': rank,
                    'Z-Score': z_score
                }
                
                records.append(record)
        
        feature_contrib_df = pd.DataFrame(records)
        print(f"  Created {len(feature_contrib_df)} feature contribution records")
        return feature_contrib_df

    # ==================== EXISTING FUNCTIONS (UNCHANGED) ====================

    def _create_background_data(self, normal_sequences, n_samples=100):
        """Create background dataset for SHAP from normal sequences."""
        n_total = len(normal_sequences)
        n_samples = min(n_samples, n_total)
        indices = np.linspace(0, n_total-1, n_samples, dtype=int)
        background = normal_sequences[indices]
        print(f"Created background dataset: {background.shape}")
        return background

    def validate_shap_quality(self, shap_values, test_sequences):
        """Validate SHAP output quality and detect potential issues."""
        report = {'status': 'PASS', 'warnings': [], 'metrics': {}}

        nan_count = np.isnan(shap_values).sum()
        inf_count = np.isinf(shap_values).sum()

        if nan_count > 0:
            report['status'] = 'FAIL'
            report['warnings'].append(f"Found {nan_count} NaN values in SHAP output")

        if inf_count > 0:
            report['status'] = 'FAIL'
            report['warnings'].append(f"Found {inf_count} Inf values in SHAP output")

        report['metrics']['nan_count'] = int(nan_count)
        report['metrics']['inf_count'] = int(inf_count)

        shap_std = np.std(shap_values, axis=0)
        low_variance_threshold = 0.001
        low_variance_features = np.where(shap_std < low_variance_threshold)[0]

        if len(low_variance_features) > 0:
            report['warnings'].append(f"Found {len(low_variance_features)} low-variance features")
            report['metrics']['low_variance_features'] = [
                self.feature_names[i] for i in low_variance_features[:10]
            ]

        feature_values = test_sequences.mean(axis=1)
        correlation_matrix = np.corrcoef(feature_values.T)

        high_corr_threshold = 0.9
        high_corr_pairs = []
        n_features = len(self.feature_names)

        for i in range(n_features):
            for j in range(i+1, n_features):
                if abs(correlation_matrix[i, j]) > high_corr_threshold:
                    high_corr_pairs.append({
                        'feature_1': self.feature_names[i],
                        'feature_2': self.feature_names[j],
                        'correlation': float(correlation_matrix[i, j])
                    })

        if len(high_corr_pairs) > 0:
            report['warnings'].append(f"Found {len(high_corr_pairs)} highly correlated feature pairs")
            report['metrics']['high_correlation_pairs'] = high_corr_pairs[:5]

        shap_range = (float(np.min(shap_values)), float(np.max(shap_values)))
        shap_mean = float(np.mean(np.abs(shap_values)))

        report['metrics']['shap_value_range'] = shap_range
        report['metrics']['mean_abs_shap'] = shap_mean

        if report['status'] == 'PASS' and len(report['warnings']) == 0:
            print("\nSHAP quality validation: PASSED")
        else:
            print(f"\nSHAP quality validation: {report['status']}")
            print(f"  Warnings: {len(report['warnings'])}")
            for warning in report['warnings']:
                print(f"  - {warning}")

        return report

    def compute_shap_values(self, test_sequences, background_sequences, max_samples=50):
        n_test = min(len(test_sequences), max_samples)
        test_subset = test_sequences[:n_test]

        print(f"\nComputing SHAP values for {n_test} samples using GradientExplainer...")

        class ReconstructionErrorModel(torch.nn.Module):
            def __init__(self, autoencoder):
                super().__init__()
                self.autoencoder = autoencoder

            def forward(self, x):
                reconstructed = self.autoencoder(x)
                mse = torch.mean((x - reconstructed) ** 2, dim=(1, 2))
                return mse.unsqueeze(-1)

        wrapper_model = ReconstructionErrorModel(self.model)
        wrapper_model.eval()

        background_tensor = torch.FloatTensor(background_sequences).to(self.device)
        test_tensor = torch.FloatTensor(test_subset).to(self.device)

        explainer = shap.GradientExplainer(wrapper_model, background_tensor)
        shap_values = explainer.shap_values(test_tensor)

        with torch.no_grad():
            base_values = wrapper_model(background_tensor).mean().item()

        if isinstance(shap_values, list):
            shap_values = np.array(shap_values[0])

        shap_values = np.squeeze(shap_values)

        if shap_values.ndim == 3:
            shap_values = shap_values.mean(axis=1)
        elif shap_values.ndim == 2 and shap_values.shape[0] != n_test:
            shap_values = shap_values.mean(axis=0, keepdims=True)
        elif shap_values.ndim == 1:
            shap_values = shap_values.reshape(1, -1)

        print(f"SHAP computation complete: {shap_values.shape}")
        return shap_values, base_values

    def global_feature_importance(self, shap_values, top_n=20):
        """Calculate global feature importance from SHAP values."""
        importance = np.abs(shap_values).mean(axis=0)

        ranking_df = pd.DataFrame({
            'feature': self.feature_names,
            'mean_abs_shap': importance,
            'importance_rank': range(1, len(importance) + 1)
        }).sort_values('mean_abs_shap', ascending=False).reset_index(drop=True)

        ranking_df['importance_rank'] = range(1, len(ranking_df) + 1)

        print(f"\nTop {top_n} features by global importance:")
        print(ranking_df.head(top_n)[['importance_rank', 'feature', 'mean_abs_shap']])

        return ranking_df

    def generate_executive_summary(self, shap_values, feature_ranking,
                                anomaly_count, total_samples, top_n=None):
        if top_n is None:
            top_n = min(5, len(feature_ranking))

        top_features = feature_ranking.head(top_n)
        top_names = top_features['feature'].tolist()
        top_importance = top_features['mean_abs_shap'].sum()
        total_importance = feature_ranking['mean_abs_shap'].sum()

        pct_explained = (top_importance / total_importance) * 100
        anomaly_rate = (anomaly_count / total_samples) * 100

        summary = f"""
    === EXECUTIVE SUMMARY: ANOMALY ANALYSIS ===
    Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

    OVERVIEW:
    - Total Samples: {total_samples:,}
    - Anomalies: {anomaly_count} ({anomaly_rate:.2f}%)
    - Features Analyzed: {len(self.feature_names)}

    KEY FINDINGS:
    Top {top_n} features explain {pct_explained:.1f}% of anomalies:
    """
        for i, (name, imp) in enumerate(zip(top_names, top_features['mean_abs_shap']), 1):
            summary += f"\n{i}. {name} (Importance: {imp:.4f})"

        summary += f"""

    RECOMMENDATION:
    Focus on top {top_n} features for root cause analysis.
    """
        return summary

    def generate_full_report(self, test_sequences, anomaly_flags, normal_sequences,
                            original_df=None, date_col='load_date', report_dates=None,
                            top_k_features=3, z_score_thresholds=None, threshold=95, 
                            output_dir='./shap_reports', n_background=100, 
                            max_anomalies=50, top_n_features=10):
        """
        Generate complete SHAP report with structured DataFrames.
        
        Args:
            test_sequences: Test sequences array
            anomaly_flags: Boolean array of anomaly flags
            normal_sequences: Normal training sequences
            original_df: Original DataFrame (required for new features)
            date_col: Date column name in original_df
            report_dates: Single date, list of dates, or None (all dates)
                         Examples: '2025-10-01', ['2025-10-01', '2025-10-05'], None
            top_k_features: Number of top features per anomaly (or 'all')
            z_score_thresholds: Custom Z-score thresholds dict
            threshold: Percentile threshold for normal range (e.g., 95, 98)
            output_dir: Output directory path
            n_background: Number of background samples for SHAP
            max_anomalies: Maximum anomalies to analyze
            top_n_features: Top N features for global importance
            
        Returns:
            dict: {'excel_report': filepath}
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        print("="*60)
        print("STARTING ENHANCED SHAP EXPLAINABILITY PIPELINE")
        print("="*60)

        anomaly_indices = np.where(anomaly_flags)[0]
        
        # Filter anomalies by date if report_dates specified
        if report_dates is not None and original_df is not None:
            filtered_indices = self._filter_anomalies_by_date(
                anomaly_indices, original_df, date_col, report_dates
            )
            if len(filtered_indices) == 0:
                print(f"\nWARNING: No anomalies found for date(s): {report_dates}")
                print("Proceeding with all anomalies instead.")
            else:
                anomaly_indices = filtered_indices
                print(f"\nFiltered to {len(anomaly_indices)} anomalies for date(s): {report_dates}")
        
        n_anomalies = min(len(anomaly_indices), max_anomalies)
        anomaly_subset = test_sequences[anomaly_indices[:n_anomalies]]

        print(f"\nAnalyzing {n_anomalies} anomalies, top {top_n_features} features")

        # SHAP computation
        background = self._create_background_data(normal_sequences, n_background)
        shap_values, base_values = self.compute_shap_values(
            anomaly_subset, background, max_samples=n_anomalies
        )

        n_display = len(self.feature_names) if top_n_features == 'all' else top_n_features
        feature_ranking = self.global_feature_importance(shap_values, top_n=n_display)

        if top_n_features != 'all':
            feature_ranking = feature_ranking.head(top_n_features)

        # Add DQ dimensions to feature ranking
        feature_ranking['dq_dimension'] = feature_ranking['feature'].apply(self._get_dq_dimension)
        feature_ranking['criticality'] = feature_ranking['dq_dimension'].apply(
            self._get_severity_from_dq_dimension
        )

        # Calculate historical stats for features in anomalies
        unique_features_in_anomalies = set()
        for idx in range(n_anomalies):
            sample_shap = shap_values[idx]
            k = top_k_features if isinstance(top_k_features, int) else 3
            top_k_idx = np.argsort(np.abs(sample_shap))[-k:][::-1]
            for feat_idx in top_k_idx:
                unique_features_in_anomalies.add(feat_idx)
        
        # Get feature names that need stats
        feature_names_subset = [self.feature_names[i] for i in unique_features_in_anomalies]
        
        # Calculate stats from ORIGINAL RAW DATA (not scaled sequences)
        historical_stats = self._calculate_historical_stats_from_df(
            original_df, feature_names_subset, threshold
        )

        # Build structured DataFrames
        if original_df is not None:
            date_range = (
                original_df[date_col].min(),
                original_df[date_col].max()
            )
            top_3_features = feature_ranking.head(3)['feature'].tolist()
            
            # Tab 2: Anomaly Details (build FIRST to calculate real severity)
            k = top_k_features if isinstance(top_k_features, int) else 3
            anomalies_df = self.build_anomalies_dataframe(
                anomaly_subset=anomaly_subset,
                shap_values=shap_values,
                anomaly_indices=anomaly_indices[:n_anomalies],
                original_df=original_df,
                historical_stats=historical_stats,
                date_col=date_col,
                top_k=k,
                z_thresholds=z_score_thresholds
            )
            
            # Tab 1: Summary (build AFTER to use real severity from anomalies_df)
            summary_df = self.build_summary_dataframe(
                anomaly_count=len(anomaly_indices),
                total_samples=len(test_sequences),
                date_range=date_range,
                columns_analyzed=len(self.feature_names),
                columns_with_anomalies=len(unique_features_in_anomalies),
                top_features=top_3_features,
                threshold=threshold,
                anomalies_df=anomalies_df
            )

            # Tab 3: Feature Contribution
            feature_contrib_df = self.build_feature_contribution_dataframe(
                anomaly_subset=anomaly_subset,
                shap_values=shap_values,
                anomaly_indices=anomaly_indices[:n_anomalies],
                original_df=original_df,
                historical_stats=historical_stats,
                date_col=date_col,
                top_k=k,
                z_thresholds=z_score_thresholds
            )
        else:
            print("\nWARNING: original_df not provided, using legacy format")
            summary_df = None
            anomalies_df = None
            feature_contrib_df = None

        # Generate plots
        plot1_bytes = self._plot_to_bytes(feature_ranking)
        plot2_bytes = self._plot_to_bytes_summary(shap_values, anomaly_subset, len(feature_ranking))

        # Export to Excel
        excel_path = self._export_direct_to_excel_v2(
            summary_df=summary_df,
            feature_ranking=feature_ranking,
            anomalies_df=anomalies_df,
            feature_contrib_df=feature_contrib_df,
            output_dir=output_path,
            image_bytes_list=[plot1_bytes, plot2_bytes]
        )

        print(f"\n{'='*60}\nExcel report: {excel_path}\n{'='*60}")
        return {'excel_report': excel_path}

    def _plot_to_bytes(self, feature_ranking):
        """Generate plot directly to bytes."""
        fig, ax = plt.subplots(figsize=(10, 8))
        ax.barh(range(len(feature_ranking)), feature_ranking['mean_abs_shap'])
        ax.set_yticks(range(len(feature_ranking)))
        ax.set_yticklabels(feature_ranking['feature'])
        ax.set_xlabel('Mean |SHAP Value|', fontsize=12)
        ax.set_title('Feature Importance', fontsize=14, fontweight='bold')
        ax.invert_yaxis()
        plt.tight_layout()

        buf = BytesIO()
        plt.savefig(buf, format='png', dpi=300, bbox_inches='tight')
        plt.close()
        buf.seek(0)
        return buf

    def _plot_to_bytes_summary(self, shap_values, test_sequences, top_n):
        """Generate SHAP summary plot to bytes."""
        feature_values = test_sequences.mean(axis=1)
        plt.figure(figsize=(10, 8))
        shap.summary_plot(shap_values, feature_values,
                         feature_names=self.feature_names,
                         max_display=top_n, show=False)

        buf = BytesIO()
        plt.savefig(buf, format='png', dpi=300, bbox_inches='tight')
        plt.close()
        buf.seek(0)
        return buf

    def _export_direct_to_excel_v2(self, summary_df, feature_ranking, anomalies_df,
                                    feature_contrib_df, output_dir, image_bytes_list):
        """
        Export structured DataFrames to Excel (new version).
        
        Args:
            summary_df: Summary DataFrame for Tab 1
            feature_ranking: Feature ranking DataFrame for Tab 2
            anomalies_df: Anomalies detail DataFrame for Tab 3
            feature_contrib_df: Feature contribution DataFrame for Tab 4
            output_dir: Output directory
            image_bytes_list: List of image BytesIO objects
            
        Returns:
            Path: Excel file path
        """
        from openpyxl.drawing.image import Image as ExcelImage

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = Path(output_dir) / f'shap_analysis_{timestamp}.xlsx'

        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            # Tab 1: Summary
            if summary_df is not None:
                summary_df.to_excel(writer, sheet_name='summary', index=False)
            
            # Tab 2: Anomalies Details
            if anomalies_df is not None:
                anomalies_df.to_excel(writer, sheet_name='Anomalies_details', index=False)
            
            # Tab 3: Feature Contribution Analysis
            if feature_contrib_df is not None:
                feature_contrib_df.to_excel(writer, sheet_name='feature_Contribution_analysis', index=False)
            
            # Tab 4: SHAP Feature Contribution (renamed from Feature Ranking)
            feature_ranking.to_excel(writer, sheet_name='shap_feat_contribution', index=False)

            # Tab 5: Visualizations
            workbook = writer.book
            viz_sheet = workbook.create_sheet('Visualizations')

            row = 1
            for img_bytes in image_bytes_list:
                img = ExcelImage(img_bytes)
                img.width = 600
                img.height = 480
                viz_sheet.add_image(img, f'A{row}')
                row += 30

        print(f"Excel report generated: {filepath}")
        return filepath

    # Keep old export function for backward compatibility
    def _export_direct_to_excel(self, summary_text, feature_ranking,
                                anomaly_details, output_dir, image_bytes_list):
        """Legacy export function (kept for backward compatibility)."""
        from openpyxl.drawing.image import Image as ExcelImage

        feature_ranking['dq_dimension'] = feature_ranking['feature'].apply(self._get_dq_dimension)
        feature_ranking['criticality'] = feature_ranking['dq_dimension'].apply(
            self._get_severity_from_dq_dimension
        )

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = Path(output_dir) / f'shap_analysis_{timestamp}.xlsx'

        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            summary_df = pd.DataFrame({'Executive Summary': summary_text.strip().split('\n')})
            summary_df.to_excel(writer, sheet_name='Executive Summary', index=False)
            feature_ranking.to_excel(writer, sheet_name='Feature Ranking', index=False)
            anomaly_details.to_excel(writer, sheet_name='Anomaly Details', index=False)

            workbook = writer.book
            viz_sheet = workbook.create_sheet('Visualizations')

            row = 1
            for img_bytes in image_bytes_list:
                img = ExcelImage(img_bytes)
                img.width = 600
                img.height = 480
                viz_sheet.add_image(img, f'A{row}')
                row += 30

        print(f"Excel report generated: {filepath}")
        return filepath




results = explainer.generate_full_report(
    test_sequences=test_sequences,
    anomaly_flags=anomaly_flags,
    normal_sequences=normal_sequences,
    original_df=selected_features_df,
    date_col='date',
    report_dates=['2025-10-01', '2025-10-05', '2025-10-10'],
    top_k_features=3,
    threshold=95,
    output_dir='./shap_reports',
    n_background=100,
    max_anomalies=50,
    top_n_features=5
)
