def _get_target_features(df, target_columns):
    """
    Extract industry-standard profiling features for anomaly detection.
    
    Args:
        df: DataFrame containing profiling metrics
        target_columns: List of base column names to monitor
        
    Returns:
        List of selected feature column names
    """
    
    # Core metrics (mandatory for anomaly detection)
    core_suffixes = [
        '_Mean',                    # Distribution center
        '_StandardDeviation',       # Variability measure
        '_CountDistinct',          # Cardinality tracking
        '_Completeness'            # Data quality indicator
    ]
    
    # Secondary metrics (data type specific)
    secondary_suffixes = [
        '_ApproxQuantiles_0.5',    # Median (robust to outliers)
        '_UniqueValueRatio',       # Diversity measure
        '_MaxLength'               # String length tracking
    ]
    
    # Combine all feature suffixes
    all_suffixes = core_suffixes + secondary_suffixes
    
    # Case-insensitive column lookup
    col_lookup = {col.lower(): col for col in df.columns}
    available_cols_lower = set(col_lookup.keys())
    
    features = []
    
    print(f"Processing {len(target_columns)} target columns...")
    
    for base_col in target_columns:
        base_lower = base_col.lower()
        
        # Direct pattern matching with wildcard for each suffix
        for suffix in all_suffixes:
            # Pattern: base_col + anything + suffix + _met_value
            pattern_matches = [
                col_lookup[lower_col] for lower_col in available_cols_lower
                if (lower_col.startswith(base_lower) and 
                    lower_col.endswith(f"{suffix.lower()}_met_value"))
            ]
            
            features.extend(pattern_matches)
        
        # Check if any features are found for this base column
        if not any(f for f in features if base_col.lower() in f.lower()):
            print(f"Warning: No profiling data found for column '{base_col}'")
    
    # Remove duplicates while preserving order
    unique_features = list(dict.fromkeys(features))
    
    # Output summary
    print(f"\nSelected {len(unique_features)} features from {len(target_columns)} target columns")
    print(f"Average features per column: {len(unique_features) / len(target_columns):.1f}")
    
    print("\nSelected features:")
    for i, feature in enumerate(unique_features, 1):
        print(f"  {i:2d}. {feature}")
    
    return unique_features
