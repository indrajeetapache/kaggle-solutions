df = spark.read \
    .option("header", True) \
    .option("nullValue", "SomeUnusedString") \
    .option("emptyValue", "") \
    .csv("data.csv")


df = spark.read \
    .option("header", True) \
    .option("nullValue", "UNUSED_PLACEHOLDER") \  # Set to a value not in your data
    .option("emptyValue", "") \                    # Explicitly map empty CSV fields to ""
    .csv("path/to/file.csv")


df = spark.read \
    .option("header", True) \
    .option("emptyValue", "") \  # This will convert empty fields to empty strings
    .csv("path/to/file.csv")

df = spark.read \
    .option("header", True) \
    .option("treatEmptyValuesAsNulls", "false") \  # Don't treat empty values as nulls
    .csv("path/to/file.csv")
with open(filepath2, 'r') as f:
    print(repr(f.read()))
df7 = spark.read \
    .option("header", True) \
    .option("nullValue", "\0") \  # Using null byte as nullValue
    .option("emptyValue", "") \
    .csv(filepath2)
