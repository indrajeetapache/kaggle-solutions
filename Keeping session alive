"""
Production-Ready SHAP Explainability for LSTM Anomaly Detection

Purpose: Generate interpretable explanations for anomalies detected by LSTM autoencoder
Audience: Technical teams and executives
Output: Global feature importance, local explanations, and executive summary
"""

import numpy as np
import pandas as pd
import shap
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime
import torch
import warnings
from io import BytesIO
warnings.filterwarnings('ignore')

class SHAPAnomalyExplainer:
    """
    SHAP-based explainability for LSTM autoencoder anomaly detection.
    
    Generates global feature importance and local explanations for anomalies.
    Outputs production-ready reports with visualizations and CSV exports.
    """
    
    def __init__(self, model, scaler, feature_names, seq_length, device='cpu'):
        """
        Initialize explainer with trained model.
        
        Args:
            model: Trained LSTMAutoencoder (PyTorch)
            scaler: Fitted StandardScaler from training
            feature_names: List of feature column names
            seq_length: Sequence length used in training
            device: torch device ('cpu' or 'cuda')
        """
        self.model = model
        self.scaler = scaler
        self.feature_names = feature_names
        self.seq_length = seq_length
        self.device = device
        self.model.eval()
        
        print(f"SHAPAnomalyExplainer initialized:")
        print(f"  - Features: {len(feature_names)}")
        print(f"  - Sequence length: {seq_length}")
        print(f"  - Device: {device}")
    
    def _create_background_data(self, normal_sequences, n_samples=100):
        """Create background dataset for SHAP from normal sequences."""
        n_total = len(normal_sequences)
        n_samples = min(n_samples, n_total)
        
        indices = np.linspace(0, n_total-1, n_samples, dtype=int)
        background = normal_sequences[indices]
        
        print(f"Created background dataset: {background.shape}")
        return background
        
    def validate_shap_quality(self, shap_values, test_sequences):
        """Validate SHAP output quality and detect potential issues."""
        report = {
            'status': 'PASS',
            'warnings': [],
            'metrics': {}
        }
        
        nan_count = np.isnan(shap_values).sum()
        inf_count = np.isinf(shap_values).sum()
        
        if nan_count > 0:
            report['status'] = 'FAIL'
            report['warnings'].append(f"Found {nan_count} NaN values in SHAP output")
        
        if inf_count > 0:
            report['status'] = 'FAIL'
            report['warnings'].append(f"Found {inf_count} Inf values in SHAP output")
        
        report['metrics']['nan_count'] = int(nan_count)
        report['metrics']['inf_count'] = int(inf_count)
        
        shap_std = np.std(shap_values, axis=0)
        low_variance_threshold = 0.001
        low_variance_features = np.where(shap_std < low_variance_threshold)[0]
        
        if len(low_variance_features) > 0:
            report['warnings'].append(
                f"Found {len(low_variance_features)} low-variance features"
            )
            report['metrics']['low_variance_features'] = [
                self.feature_names[i] for i in low_variance_features[:10]
            ]
        
        feature_values = test_sequences.mean(axis=1)
        correlation_matrix = np.corrcoef(feature_values.T)
        
        high_corr_threshold = 0.9
        high_corr_pairs = []
        n_features = len(self.feature_names)
        
        for i in range(n_features):
            for j in range(i+1, n_features):
                if abs(correlation_matrix[i, j]) > high_corr_threshold:
                    high_corr_pairs.append({
                        'feature_1': self.feature_names[i],
                        'feature_2': self.feature_names[j],
                        'correlation': float(correlation_matrix[i, j])
                    })
        
        if len(high_corr_pairs) > 0:
            report['warnings'].append(
                f"Found {len(high_corr_pairs)} highly correlated feature pairs"
            )
            report['metrics']['high_correlation_pairs'] = high_corr_pairs[:5]
        
        shap_range = (float(np.min(shap_values)), float(np.max(shap_values)))
        shap_mean = float(np.mean(np.abs(shap_values)))
        
        report['metrics']['shap_value_range'] = shap_range
        report['metrics']['mean_abs_shap'] = shap_mean
        
        if report['status'] == 'PASS' and len(report['warnings']) == 0:
            print("\nSHAP quality validation: PASSED")
        else:
            print(f"\nSHAP quality validation: {report['status']}")
            print(f"  Warnings: {len(report['warnings'])}")
            for warning in report['warnings']:
                print(f"  - {warning}")
        
        return report
        
    def compute_shap_values(self, test_sequences, background_sequences, max_samples=50):
        n_test = min(len(test_sequences), max_samples)
        test_subset = test_sequences[:n_test]
        
        print(f"\nComputing SHAP values for {n_test} samples using GradientExplainer...")
        
        class ReconstructionErrorModel(torch.nn.Module):
            def __init__(self, autoencoder):
                super().__init__()
                self.autoencoder = autoencoder
            
            def forward(self, x):
                reconstructed = self.autoencoder(x)
                mse = torch.mean((x - reconstructed) ** 2, dim=(1, 2))
                return mse.unsqueeze(-1)
        
        wrapper_model = ReconstructionErrorModel(self.model)
        wrapper_model.eval()
        
        background_tensor = torch.FloatTensor(background_sequences).to(self.device)
        test_tensor = torch.FloatTensor(test_subset).to(self.device)
        
        explainer = shap.GradientExplainer(wrapper_model, background_tensor)
        shap_values = explainer.shap_values(test_tensor)
        
        with torch.no_grad():
            base_values = wrapper_model(background_tensor).mean().item()
        
        if isinstance(shap_values, list):
            shap_values = np.array(shap_values[0])
        
        shap_values = np.squeeze(shap_values)
        
        if shap_values.ndim == 3:
            shap_values = shap_values.mean(axis=1)
        elif shap_values.ndim == 2 and shap_values.shape[0] != n_test:
            shap_values = shap_values.mean(axis=0, keepdims=True)
        elif shap_values.ndim == 1:
            shap_values = shap_values.reshape(1, -1)
        
        print(f"SHAP computation complete: {shap_values.shape}")
        return shap_values, base_values    

    def global_feature_importance(self, shap_values, top_n=20):
        """Calculate global feature importance from SHAP values."""
        importance = np.abs(shap_values).mean(axis=0)
        
        ranking_df = pd.DataFrame({
            'feature': self.feature_names,
            'mean_abs_shap': importance,
            'importance_rank': range(1, len(importance) + 1)
        }).sort_values('mean_abs_shap', ascending=False).reset_index(drop=True)
        
        ranking_df['importance_rank'] = range(1, len(ranking_df) + 1)
        
        print(f"\nTop {top_n} features by global importance:")
        print(ranking_df.head(top_n)[['importance_rank', 'feature', 'mean_abs_shap']])
        
        return ranking_df
    
    def generate_executive_summary(self, shap_values, feature_ranking, 
                                anomaly_count, total_samples, top_n=None):
        if top_n is None:
            top_n = min(5, len(feature_ranking))
        
        top_features = feature_ranking.head(top_n)
        top_names = top_features['feature'].tolist()
        top_importance = top_features['mean_abs_shap'].sum()
        total_importance = feature_ranking['mean_abs_shap'].sum()
        
        pct_explained = (top_importance / total_importance) * 100
        anomaly_rate = (anomaly_count / total_samples) * 100
        
        summary = f"""
    === EXECUTIVE SUMMARY: ANOMALY ANALYSIS ===
    Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

    OVERVIEW:
    - Total Samples: {total_samples:,}
    - Anomalies: {anomaly_count} ({anomaly_rate:.2f}%)
    - Features Analyzed: {len(self.feature_names)}

    KEY FINDINGS:
    Top {top_n} features explain {pct_explained:.1f}% of anomalies:
    """
        for i, (name, imp) in enumerate(zip(top_names, top_features['mean_abs_shap']), 1):
            summary += f"\n{i}. {name} (Importance: {imp:.4f})"
        
        summary += f"""

    RECOMMENDATION:
    Focus on top {top_n} features for root cause analysis.
    """
        return summary

    def generate_full_report(self, test_sequences, anomaly_flags, 
                            normal_sequences, output_dir='./shap_reports',
                            n_background=100, max_anomalies=50, top_n_features=10):
        """Generate SHAP report - direct to Excel, no temp files."""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        print("="*60)
        print("STARTING SHAP EXPLAINABILITY PIPELINE")
        print("="*60)
        
        anomaly_indices = np.where(anomaly_flags)[0]
        n_anomalies = min(len(anomaly_indices), max_anomalies)
        anomaly_subset = test_sequences[anomaly_indices[:n_anomalies]]
        
        print(f"\nAnalyzing {n_anomalies} anomalies, top {top_n_features} features")
        
        background = self._create_background_data(normal_sequences, n_background)
        shap_values, base_values = self.compute_shap_values(
            anomaly_subset, background, max_samples=n_anomalies
        )
        
        n_display = len(self.feature_names) if top_n_features == 'all' else top_n_features
        feature_ranking = self.global_feature_importance(shap_values, top_n=n_display)
        
        if top_n_features != 'all':
            feature_ranking = feature_ranking.head(top_n_features)
        
        summary = self.generate_executive_summary(
            shap_values, feature_ranking, len(anomaly_indices), 
            len(test_sequences), top_n=top_n_features if top_n_features != 'all' else 10
        )
        
        # Create anomaly details in-memory (no CSV)
        top_k = min(3, top_n_features if isinstance(top_n_features, int) else 3)
        records = []
        for idx in range(n_anomalies):
            sample_shap = shap_values[idx]
            top_k_idx = np.argsort(np.abs(sample_shap))[-top_k:][::-1]
            feature_vals = anomaly_subset[idx].mean(axis=0)
            
            record = {'anomaly_index': idx}
            for i, feat_idx in enumerate(top_k_idx, 1):
                record[f'top_{i}_feature'] = self.feature_names[feat_idx]
                record[f'top_{i}_shap_value'] = sample_shap[feat_idx]
                record[f'top_{i}_feature_value'] = feature_vals[feat_idx]
            records.append(record)
        
        details_df = pd.DataFrame(records)
        
        # Generate plots in-memory
        plot1_bytes = self._plot_to_bytes(feature_ranking)
        plot2_bytes = self._plot_to_bytes_summary(shap_values, anomaly_subset, len(feature_ranking))
        
        # Write everything directly to Excel
        excel_path = self._export_direct_to_excel(
            summary, feature_ranking, details_df, output_path, [plot1_bytes, plot2_bytes]
        )
        
        print(f"\n{'='*60}\nExcel report: {excel_path}\n{'='*60}")
        return {'excel_report': excel_path}

    def _plot_to_bytes(self, feature_ranking):
        """Generate plot directly to bytes (no disk I/O)."""
        fig, ax = plt.subplots(figsize=(10, 8))
        ax.barh(range(len(feature_ranking)), feature_ranking['mean_abs_shap'])
        ax.set_yticks(range(len(feature_ranking)))
        ax.set_yticklabels(feature_ranking['feature'])
        ax.set_xlabel('Mean |SHAP Value|', fontsize=12)
        ax.set_title('Feature Importance', fontsize=14, fontweight='bold')
        ax.invert_yaxis()
        plt.tight_layout()
        
        buf = BytesIO()
        plt.savefig(buf, format='png', dpi=300, bbox_inches='tight')
        plt.close()
        buf.seek(0)
        return buf

    def _plot_to_bytes_summary(self, shap_values, test_sequences, top_n):
        """Generate SHAP summary plot to bytes."""
        feature_values = test_sequences.mean(axis=1)
        plt.figure(figsize=(10, 8))
        shap.summary_plot(shap_values, feature_values, 
                         feature_names=self.feature_names, 
                         max_display=top_n, show=False)
        
        buf = BytesIO()
        plt.savefig(buf, format='png', dpi=300, bbox_inches='tight')
        plt.close()
        buf.seek(0)
        return buf

    def _export_direct_to_excel(self, summary_text, feature_ranking, 
                                anomaly_details, output_dir, image_bytes_list):
        """Write directly to Excel - no temp files."""
        from openpyxl.drawing.image import Image as ExcelImage
        
        DQ_KEYWORDS = {
            'Completeness': ['completeness', 'missing', 'null', 'isnotnull'],
            'Accuracy': ['accuracy', 'entropy', 'zscore', 'outlier', 'anomaly', 'mean', 'sum', 'count'],
            'Consistency': ['consistency', 'standarddeviation', 'variance', 'correlation'],
            'Validity': ['validity', 'minimum', 'maximum', 'datatype', 'pattern', 'regex'],
            'Uniqueness': ['uniqueness', 'countdistinct', 'distinctness', 'duplicate'],
            'Timeliness': ['timeliness', 'freshness', 'lag', 'delay', 'timestamp']
        }
        
        criticality_map = {
            'Accuracy': 'Critical', 'Completeness': 'Critical', 'Consistency': 'Critical',
            'Timeliness': 'Warning', 'Validity': 'Warning', 'Uniqueness': 'Warning'
        }
        
        def get_dq_dimension(feature_name):
            feature_lower = feature_name.lower()
            return next((dim for dim, keywords in DQ_KEYWORDS.items() 
                        if any(kw in feature_lower for kw in keywords)), 'Unknown')
        
        feature_ranking['dq_dimension'] = feature_ranking['feature'].apply(get_dq_dimension)
        feature_ranking['criticality'] = feature_ranking['dq_dimension'].map(criticality_map).fillna('Unknown')
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = Path(output_dir) / f'shap_analysis_{timestamp}.xlsx'
        
        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            summary_df = pd.DataFrame({'Executive Summary': summary_text.strip().split('\n')})
            summary_df.to_excel(writer, sheet_name='Executive Summary', index=False)
            feature_ranking.to_excel(writer, sheet_name='Feature Ranking', index=False)
            anomaly_details.to_excel(writer, sheet_name='Anomaly Details', index=False)
            
            workbook = writer.book
            viz_sheet = workbook.create_sheet('Visualizations')
            
            row = 1
            for img_bytes in image_bytes_list:
                img = ExcelImage(img_bytes)
                img.width = 600
                img.height = 480
                viz_sheet.add_image(img, f'A{row}')
                row += 30
        
        print(f"Excel report generated: {filepath}")
        return filepath
