"""
Enhanced SHAP Explainability for LSTM Anomaly Detection
Complete implementation with Phase 1 helpers and Phase 2 DataFrame builders

New capabilities:
- Historical statistics calculation
- Anomaly-to-original data mapping
- Business description generation
- Structured DataFrame outputs for all report tabs
- Configurable parameters for flexibility
"""

import numpy as np
import pandas as pd
import shap
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime
import torch
import warnings
from io import BytesIO
warnings.filterwarnings('ignore')

class SHAPAnomalyExplainer:
    """
    SHAP-based explainability for LSTM autoencoder anomaly detection.
    Generates structured Excel reports with global and local explanations.
    """

    def __init__(self, model, scaler, feature_names, seq_length, device='cpu'):
        """
        Initialize explainer with trained model.

        Args:
            model: Trained LSTMAutoencoder (PyTorch)
            scaler: Fitted StandardScaler from training
            feature_names: List of feature column names
            seq_length: Sequence length used in training
            device: torch device ('cpu' or 'cuda')
        """
        self.model = model
        self.scaler = scaler
        self.feature_names = feature_names
        self.seq_length = seq_length
        self.device = device
        self.model.eval()

        print(f"SHAPAnomalyExplainer initialized:")
        print(f"  - Features: {len(feature_names)}")
        print(f"  - Sequence length: {seq_length}")
        print(f"  - Device: {device}")

    # ==================== PHASE 1: HELPER FUNCTIONS ====================
    
    def _calculate_historical_stats_from_df(self, original_df, feature_names_subset, threshold=95):
        """
        Calculate historical statistics from RAW original DataFrame.
        This ensures stats match the original unscaled data distribution.
        
        Args:
            original_df: Original unscaled DataFrame
            feature_names_subset: List of feature names to compute
            threshold: Percentile threshold (e.g., 95, 98)
            
        Returns:
            dict: {feature_name: {'mean': X, 'std': Y, 'p_lower': Z, 'p_upper': W, ...}}
        """
        print(f"\nCalculating historical stats from RAW data (threshold={threshold}%)...")
        
        p_lower = (100 - threshold) / 2
        p_upper = 100 - p_lower
        
        historical_stats = {}
        
        for feature_name in feature_names_subset:
            if feature_name not in original_df.columns:
                continue
                
            feature_values = original_df[feature_name].values
            
            stats = {
                'mean': float(np.mean(feature_values)),
                'std': float(np.std(feature_values)),
                'min': float(np.min(feature_values)),
                'max': float(np.max(feature_values)),
                'p_lower': float(np.percentile(feature_values, p_lower)),
                'p25': float(np.percentile(feature_values, 25)),
                'p50': float(np.percentile(feature_values, 50)),
                'p75': float(np.percentile(feature_values, 75)),
                'p_upper': float(np.percentile(feature_values, p_upper)),
                'threshold': threshold
            }
            
            historical_stats[feature_name] = stats
        
        print(f"  Computed RAW stats for {len(historical_stats)} features (P{p_lower:.1f}-P{p_upper:.1f})")
        return historical_stats
    
    def _calculate_historical_stats(self, normal_sequences, feature_subset=None, threshold=95):
        """
        Calculate historical statistics from normal training sequences.
        Computes mean, std, min, max, and percentiles for each feature.
        
        Args:
            normal_sequences: Array (n_samples, seq_length, n_features)
            feature_subset: List of feature indices (None = all features)
            threshold: Percentile threshold (e.g., 95 for 95th percentile)
            
        Returns:
            dict: {feature_name: {'mean': X, 'std': Y, 'p_lower': Z, 'p_upper': W, ...}}
        """
        print(f"\nCalculating historical statistics (threshold={threshold}%) from normal sequences...")
        
        if feature_subset is None:
            feature_subset = range(len(self.feature_names))
        
        # Calculate complementary percentiles
        p_lower = (100 - threshold) / 2
        p_upper = 100 - p_lower
        
        historical_stats = {}
        
        for feat_idx in feature_subset:
            feature_name = self.feature_names[feat_idx]
            feature_values = normal_sequences[:, :, feat_idx].flatten()
            
            stats = {
                'mean': float(np.mean(feature_values)),
                'std': float(np.std(feature_values)),
                'min': float(np.min(feature_values)),
                'max': float(np.max(feature_values)),
                'p_lower': float(np.percentile(feature_values, p_lower)),
                'p25': float(np.percentile(feature_values, 25)),
                'p50': float(np.percentile(feature_values, 50)),
                'p75': float(np.percentile(feature_values, 75)),
                'p_upper': float(np.percentile(feature_values, p_upper)),
                'threshold': threshold
            }
            
            historical_stats[feature_name] = stats
        
        print(f"  Computed stats for {len(historical_stats)} features (P{p_lower:.1f}-P{p_upper:.1f})")
        return historical_stats
    
    def _map_anomaly_to_original_data(self, anomaly_indices, original_df, date_col='load_date'):
        """
        Map detected anomaly indices back to original DataFrame rows.
        Extracts timestamps and creates pipeline IDs.
        
        Args:
            anomaly_indices: Array of anomaly positions in test sequences
            original_df: Original DataFrame used for LSTM
            date_col: Name of date/timestamp column
            
        Returns:
            DataFrame: ['anomaly_index', 'pipeline_id', 'timestamp', 'original_row_idx']
        """
        print(f"\nMapping {len(anomaly_indices)} anomalies to original data...")
        
        mapping_records = []
        
        for idx, anomaly_idx in enumerate(anomaly_indices):
            original_row = anomaly_idx + self.seq_length - 1
            
            if original_row < len(original_df):
                timestamp = original_df.iloc[original_row][date_col]
            else:
                timestamp = pd.NaT
            
            timestamp_str = pd.to_datetime(timestamp).strftime('%Y%m%d_%H%M%S') \
                           if pd.notna(timestamp) else 'UNKNOWN'
            pipeline_id = f"ANOM_{timestamp_str}_{idx:04d}"
            
            mapping_records.append({
                'anomaly_index': anomaly_idx,
                'pipeline_id': pipeline_id,
                'timestamp': timestamp,
                'original_row_idx': original_row
            })
        
        mapping_df = pd.DataFrame(mapping_records)
        print(f"  Successfully mapped {len(mapping_df)} anomalies")
        return mapping_df
    
    def _generate_business_description(self, z_score, feature_value, normal_range, 
                                        feature_name, z_thresholds=None):
        """
        Generate human-readable description of anomaly severity.
        Uses Z-score and feature context for business-friendly text.
        
        Args:
            z_score: Calculated Z-score
            feature_value: Actual feature value
            normal_range: String representation (e.g., "10-50")
            feature_name: Feature name
            z_thresholds: Dict with severity thresholds
            
        Returns:
            str: Business description
        """
        if z_thresholds is None:
            z_thresholds = {
                'extreme_high': 3.0,
                'extreme_low': -3.0,
                'significant_high': 2.0,
                'significant_low': -2.0,
                'moderate_high': 1.5,
                'moderate_low': -1.5
            }
        
        if z_score >= z_thresholds['extreme_high']:
            severity = "Extremely higher"
        elif z_score <= z_thresholds['extreme_low']:
            severity = "Extremely lower"
        elif z_score >= z_thresholds['significant_high']:
            severity = "Significantly higher"
        elif z_score <= z_thresholds['significant_low']:
            severity = "Significantly lower"
        elif z_score >= z_thresholds['moderate_high']:
            severity = "Moderately higher"
        elif z_score <= z_thresholds['moderate_low']:
            severity = "Moderately lower"
        else:
            severity = "Slightly different"
        
        description = f"{severity} than normal (Z-score: {z_score:.2f}). "
        description += f"Value: {feature_value:.2f}, Normal range: {normal_range}"
        
        return description
    
    def _get_dq_dimension(self, feature_name):
        """Map feature name to Data Quality dimension based on keywords."""
        DQ_KEYWORDS = {
            'Completeness': ['completeness', 'missing', 'null', 'isnotnull'],
            'Accuracy': ['accuracy', 'entropy', 'zscore', 'outlier', 'anomaly', 
                        'mean', 'sum', 'count'],
            'Consistency': ['consistency', 'standarddeviation', 'variance', 'correlation'],
            'Validity': ['validity', 'minimum', 'maximum', 'datatype', 'pattern', 'regex'],
            'Uniqueness': ['uniqueness', 'countdistinct', 'distinctness', 'duplicate'],
            'Timeliness': ['timeliness', 'freshness', 'lag', 'delay', 'timestamp']
        }
        
        feature_lower = feature_name.lower()
        for dimension, keywords in DQ_KEYWORDS.items():
            if any(kw in feature_lower for kw in keywords):
                return dimension
        return 'Unknown'
    
    def _get_severity_from_dq_dimension(self, dq_dimension):
        """Map DQ dimension to severity level."""
        criticality_map = {
            'Accuracy': 'Critical',
            'Completeness': 'Critical',
            'Consistency': 'Critical',
            'Timeliness': 'Warning',
            'Validity': 'Warning',
            'Uniqueness': 'Warning',
            'Unknown': 'Unknown'
        }
        return criticality_map.get(dq_dimension, 'Unknown')
    
    def _filter_anomalies_by_date(self, anomaly_indices, original_df, date_col, report_dates):
        """
        Filter anomaly indices to only include specified dates.
        
        Args:
            anomaly_indices: Array of anomaly positions
            original_df: Original DataFrame with date column
            date_col: Name of date column
            report_dates: Single date string, list of dates, or None
            
        Returns:
            np.array: Filtered anomaly indices
        """
        # Convert report_dates to list if single date
        if isinstance(report_dates, str):
            report_dates = [report_dates]
        
        # Convert to datetime for comparison
        report_dates = [pd.to_datetime(d).date() for d in report_dates]
        
        filtered_indices = []
        
        for anomaly_idx in anomaly_indices:
            # Calculate original row index (last timestep of sequence)
            original_row = anomaly_idx + self.seq_length - 1
            
            if original_row < len(original_df):
                row_date = pd.to_datetime(original_df.iloc[original_row][date_col]).date()
                
                if row_date in report_dates:
                    filtered_indices.append(anomaly_idx)
        
        return np.array(filtered_indices)

    # ==================== PHASE 2: DATAFRAME BUILDERS ====================
    
    def build_summary_dataframe(self, anomaly_count, total_samples, date_range,
                                 columns_analyzed, columns_with_anomalies,
                                 top_features, threshold, anomalies_df=None):
        """
        Build structured summary DataFrame for Tab 1.
        
        Args:
            anomaly_count: Total anomalies detected
            total_samples: Total samples analyzed
            date_range: Tuple (start_date, end_date)
            columns_analyzed: Number of features
            columns_with_anomalies: Number of features with anomalies
            top_features: List of top feature names
            threshold: Anomaly detection threshold
            anomalies_df: Anomalies DataFrame to calculate real severity breakdown
            
        Returns:
            DataFrame: Summary metrics
        """
        print("\nBuilding summary DataFrame...")
        
        # Calculate REAL severity breakdown from anomalies_df
        if anomalies_df is not None and 'Severity' in anomalies_df.columns:
            severity_counts = anomalies_df['Severity'].value_counts()
            critical_anomalies = severity_counts.get('Critical', 0)
            high_anomalies = severity_counts.get('Warning', 0)
            low_anomalies = severity_counts.get('Unknown', 0)
        else:
            # Fallback if anomalies_df not provided
            critical_anomalies = 0
            high_anomalies = 0
            low_anomalies = anomaly_count
        
        date_range_str = f"{date_range[0]} to {date_range[1]}"
        top_features_str = ", ".join(top_features)
        
        summary_df = pd.DataFrame({
            'Metric': [
                'Total Anomalies Detected',
                'Critical Anomalies',
                'High Anomalies',
                'Low Anomalies',
                'Date Range',
                'Columns Analyzed',
                'Columns w/ Anomalies',
                'Top 3 Anomalous Features',
                'Threshold'
            ],
            'Value': [
                anomaly_count,
                critical_anomalies,
                high_anomalies,
                low_anomalies,
                date_range_str,
                columns_analyzed,
                columns_with_anomalies,
                top_features_str,
                threshold
            ]
        })
        
        print(f"  Summary created with {len(summary_df)} metrics")
        return summary_df
    
    def build_anomalies_dataframe(self, anomaly_subset, shap_values, anomaly_indices,
                                   original_df, historical_stats, date_col='load_date',
                                   top_k=3, z_thresholds=None):
        """
        Build detailed anomalies DataFrame for Tab 2.
        
        Args:
            anomaly_subset: Anomaly sequences (n_anomalies, seq_length, n_features)
            shap_values: SHAP values (n_anomalies, n_features)
            anomaly_indices: Original indices of anomalies
            original_df: Original DataFrame
            historical_stats: Dict from _calculate_historical_stats()
            date_col: Date column name
            top_k: Number of top features per anomaly
            z_thresholds: Custom Z-score thresholds
            
        Returns:
            DataFrame: Detailed anomaly records
        """
        print(f"\nBuilding anomalies DataFrame for {len(anomaly_subset)} anomalies...")
        
        # Map anomalies to original data
        mapping_df = self._map_anomaly_to_original_data(anomaly_indices, original_df, date_col)
        
        records = []
        
        for idx in range(len(anomaly_subset)):
            sample_shap = shap_values[idx]
            top_k_idx = np.argsort(np.abs(sample_shap))[-top_k:][::-1]
            
            # Get raw values from original DataFrame
            original_row_idx = mapping_df.iloc[idx]['original_row_idx']
            
            pipeline_id = mapping_df.iloc[idx]['pipeline_id']
            timestamp = mapping_df.iloc[idx]['timestamp']
            
            for rank, feat_idx in enumerate(top_k_idx, 1):
                feature_name = self.feature_names[feat_idx]
                
                # Extract RAW value from original DataFrame
                raw_feature_value = original_df.iloc[original_row_idx][feature_name]
                
                shap_value = sample_shap[feat_idx]
                
                # Get historical stats (computed from raw data)
                stats = historical_stats.get(feature_name, {})
                hist_mean = stats.get('mean', 0)
                hist_std = stats.get('std', 1)
                hist_min = stats.get('min', 0)
                hist_max = stats.get('max', 0)
                hist_p_lower = stats.get('p_lower', 0)
                hist_p_upper = stats.get('p_upper', 0)
                
                # Calculate metrics using RAW values
                z_score = (raw_feature_value - hist_mean) / hist_std if hist_std > 0 else 0
                expected_value = hist_mean
                difference = raw_feature_value - expected_value
                deviation_pct = (difference / expected_value * 100) if expected_value != 0 else 0
                normal_range = f"{hist_p_lower:.2f}-{hist_p_upper:.2f}"
                
                # Get scaled value for reference
                scaled_feature_value = anomaly_subset[idx].mean(axis=0)[feat_idx]
                
                # DQ dimension and severity
                dq_dimension = self._get_dq_dimension(feature_name)
                severity = self._get_severity_from_dq_dimension(dq_dimension)
                
                # Business description using RAW values
                description = self._generate_business_description(
                    z_score, raw_feature_value, normal_range, feature_name, z_thresholds
                )
                
                record = {
                    'pipeline_id': pipeline_id,
                    'Timestamp': timestamp,
                    'column_name': feature_name,
                    'Feature_Name': feature_name,
                    'dq_dimension': dq_dimension,
                    'Severity': severity,
                    'Anomaly_Score': abs(shap_value),
                    'Raw_Value': raw_feature_value,
                    'Scaled_Value': scaled_feature_value,
                    'Expected_Value': expected_value,
                    'Difference': difference,
                    'Deviation_%': deviation_pct,
                    'Historical_Mean': hist_mean,
                    'Historical_Std': hist_std,
                    'Historical_Min': hist_min,
                    'Historical_Max': hist_max,
                    'Normal_Range': normal_range,
                    'Z-Score': z_score,
                    'Description': description
                }
                
                records.append(record)
        
        anomalies_df = pd.DataFrame(records)
        print(f"  Created {len(anomalies_df)} anomaly detail records")
        return anomalies_df
    
    def build_feature_contribution_dataframe(self, anomaly_subset, shap_values,
                                              anomaly_indices, original_df,
                                              historical_stats, date_col='load_date',
                                              top_k=3, z_thresholds=None):
        """
        Build feature contribution DataFrame for Tab 3.
        
        Args:
            anomaly_subset: Anomaly sequences
            shap_values: SHAP values
            anomaly_indices: Original indices
            original_df: Original DataFrame
            historical_stats: Historical statistics dict
            date_col: Date column name
            top_k: Number of top features per anomaly
            z_thresholds: Custom Z-score thresholds
            
        Returns:
            DataFrame: Feature contribution details
        """
        print(f"\nBuilding feature contribution DataFrame...")
        
        mapping_df = self._map_anomaly_to_original_data(anomaly_indices, original_df, date_col)
        
        records = []
        
        for idx in range(len(anomaly_subset)):
            sample_shap = shap_values[idx]
            top_k_idx = np.argsort(np.abs(sample_shap))[-top_k:][::-1]
            
            # Get raw values from original DataFrame
            original_row_idx = mapping_df.iloc[idx]['original_row_idx']
            pipeline_id = mapping_df.iloc[idx]['pipeline_id']
            
            for rank, feat_idx in enumerate(top_k_idx, 1):
                feature_name = self.feature_names[feat_idx]
                
                # Extract RAW value from original DataFrame
                raw_feature_value = original_df.iloc[original_row_idx][feature_name]
                scaled_feature_value = anomaly_subset[idx].mean(axis=0)[feat_idx]
                
                contribution_score = abs(sample_shap[feat_idx])
                
                stats = historical_stats.get(feature_name, {})
                hist_mean = stats.get('mean', 0)
                hist_std = stats.get('std', 1)
                hist_p_lower = stats.get('p_lower', 0)
                hist_p_upper = stats.get('p_upper', 0)
                
                z_score = (raw_feature_value - hist_mean) / hist_std if hist_std > 0 else 0
                normal_range = f"{hist_p_lower:.2f}-{hist_p_upper:.2f}"
                
                description = self._generate_business_description(
                    z_score, raw_feature_value, normal_range, feature_name, z_thresholds
                )
                
                record = {
                    'pipeline_id': pipeline_id,
                    'Feature_Name': feature_name,
                    'Raw_Value': raw_feature_value,
                    'Scaled_Value': scaled_feature_value,
                    'Normal_Range': normal_range,
                    'Contribution_Score': contribution_score,
                    'Business_Description': description,
                    'Contribution_Rank': rank,
                    'Z-Score': z_score
                }
                
                records.append(record)
        
        feature_contrib_df = pd.DataFrame(records)
        print(f"  Created {len(feature_contrib_df)} feature contribution records")
        return feature_contrib_df

    # ==================== EXISTING FUNCTIONS (UNCHANGED) ====================

    def _create_background_data(self, normal_sequences, n_samples=100):
        """Create background dataset for SHAP from normal sequences."""
        n_total = len(normal_sequences)
        n_samples = min(n_samples, n_total)
        indices = np.linspace(0, n_total-1, n_samples, dtype=int)
        background = normal_sequences[indices]
        print(f"Created background dataset: {background.shape}")
        return background

    def validate_shap_quality(self, shap_values, test_sequences):
        """Validate SHAP output quality and detect potential issues."""
        report = {'status': 'PASS', 'warnings': [], 'metrics': {}}

        nan_count = np.isnan(shap_values).sum()
        inf_count = np.isinf(shap_values).sum()

        if nan_count > 0:
            report['status'] = 'FAIL'
            report['warnings'].append(f"Found {nan_count} NaN values in SHAP output")

        if inf_count > 0:
            report['status'] = 'FAIL'
            report['warnings'].append(f"Found {inf_count} Inf values in SHAP output")

        report['metrics']['nan_count'] = int(nan_count)
        report['metrics']['inf_count'] = int(inf_count)

        shap_std = np.std(shap_values, axis=0)
        low_variance_threshold = 0.001
        low_variance_features = np.where(shap_std < low_variance_threshold)[0]

        if len(low_variance_features) > 0:
            report['warnings'].append(f"Found {len(low_variance_features)} low-variance features")
            report['metrics']['low_variance_features'] = [
                self.feature_names[i] for i in low_variance_features[:10]
            ]

        feature_values = test_sequences.mean(axis=1)
        correlation_matrix = np.corrcoef(feature_values.T)

        high_corr_threshold = 0.9
        high_corr_pairs = []
        n_features = len(self.feature_names)

        for i in range(n_features):
            for j in range(i+1, n_features):
                if abs(correlation_matrix[i, j]) > high_corr_threshold:
                    high_corr_pairs.append({
                        'feature_1': self.feature_names[i],
                        'feature_2': self.feature_names[j],
                        'correlation': float(correlation_matrix[i, j])
                    })

        if len(high_corr_pairs) > 0:
            report['warnings'].append(f"Found {len(high_corr_pairs)} highly correlated feature pairs")
            report['metrics']['high_correlation_pairs'] = high_corr_pairs[:5]

        shap_range = (float(np.min(shap_values)), float(np.max(shap_values)))
        shap_mean = float(np.mean(np.abs(shap_values)))

        report['metrics']['shap_value_range'] = shap_range
        report['metrics']['mean_abs_shap'] = shap_mean

        if report['status'] == 'PASS' and len(report['warnings']) == 0:
            print("\nSHAP quality validation: PASSED")
        else:
            print(f"\nSHAP quality validation: {report['status']}")
            print(f"  Warnings: {len(report['warnings'])}")
            for warning in report['warnings']:
                print(f"  - {warning}")

        return report

    def compute_shap_values(self, test_sequences, background_sequences, max_samples=50):
        n_test = min(len(test_sequences), max_samples)
        test_subset = test_sequences[:n_test]

        print(f"\nComputing SHAP values for {n_test} samples using GradientExplainer...")

        class ReconstructionErrorModel(torch.nn.Module):
            def __init__(self, autoencoder):
                super().__init__()
                self.autoencoder = autoencoder

            def forward(self, x):
                reconstructed = self.autoencoder(x)
                mse = torch.mean((x - reconstructed) ** 2, dim=(1, 2))
                return mse.unsqueeze(-1)

        wrapper_model = ReconstructionErrorModel(self.model)
        wrapper_model.eval()

        background_tensor = torch.FloatTensor(background_sequences).to(self.device)
        test_tensor = torch.FloatTensor(test_subset).to(self.device)

        explainer = shap.GradientExplainer(wrapper_model, background_tensor)
        shap_values = explainer.shap_values(test_tensor)

        with torch.no_grad():
            base_values = wrapper_model(background_tensor).mean().item()

        if isinstance(shap_values, list):
            shap_values = np.array(shap_values[0])

        shap_values = np.squeeze(shap_values)

        if shap_values.ndim == 3:
            shap_values = shap_values.mean(axis=1)
        elif shap_values.ndim == 2 and shap_values.shape[0] != n_test:
            shap_values = shap_values.mean(axis=0, keepdims=True)
        elif shap_values.ndim == 1:
            shap_values = shap_values.reshape(1, -1)

        print(f"SHAP computation complete: {shap_values.shape}")
        return shap_values, base_values

    def global_feature_importance(self, shap_values, top_n=20):
        """Calculate global feature importance from SHAP values."""
        importance = np.abs(shap_values).mean(axis=0)

        ranking_df = pd.DataFrame({
            'feature': self.feature_names,
            'mean_abs_shap': importance,
            'importance_rank': range(1, len(importance) + 1)
        }).sort_values('mean_abs_shap', ascending=False).reset_index(drop=True)

        ranking_df['importance_rank'] = range(1, len(ranking_df) + 1)

        print(f"\nTop {top_n} features by global importance:")
        print(ranking_df.head(top_n)[['importance_rank', 'feature', 'mean_abs_shap']])

        return ranking_df

    def generate_executive_summary(self, shap_values, feature_ranking,
                                anomaly_count, total_samples, top_n=None):
        if top_n is None:
            top_n = min(5, len(feature_ranking))

        top_features = feature_ranking.head(top_n)
        top_names = top_features['feature'].tolist()
        top_importance = top_features['mean_abs_shap'].sum()
        total_importance = feature_ranking['mean_abs_shap'].sum()

        pct_explained = (top_importance / total_importance) * 100
        anomaly_rate = (anomaly_count / total_samples) * 100

        summary = f"""
    === EXECUTIVE SUMMARY: ANOMALY ANALYSIS ===
    Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

    OVERVIEW:
    - Total Samples: {total_samples:,}
    - Anomalies: {anomaly_count} ({anomaly_rate:.2f}%)
    - Features Analyzed: {len(self.feature_names)}

    KEY FINDINGS:
    Top {top_n} features explain {pct_explained:.1f}% of anomalies:
    """
        for i, (name, imp) in enumerate(zip(top_names, top_features['mean_abs_shap']), 1):
            summary += f"\n{i}. {name} (Importance: {imp:.4f})"

        summary += f"""

    RECOMMENDATION:
    Focus on top {top_n} features for root cause analysis.
    """
        return summary

    def generate_full_report(self, test_sequences, anomaly_flags, normal_sequences,
                            original_df=None, date_col='load_date', report_dates=None,
                            top_k_features=3, z_score_thresholds=None, threshold=95, 
                            output_dir='./shap_reports', n_background=100, 
                            max_anomalies=50, top_n_features=10):
        """
        Generate complete SHAP report with structured DataFrames.
        
        Args:
            test_sequences: Test sequences array
            anomaly_flags: Boolean array of anomaly flags
            normal_sequences: Normal training sequences
            original_df: Original DataFrame (required for new features)
            date_col: Date column name in original_df
            report_dates: Single date, list of dates, or None (all dates)
                         Examples: '2025-10-01', ['2025-10-01', '2025-10-05'], None
            top_k_features: Number of top features per anomaly (or 'all')
            z_score_thresholds: Custom Z-score thresholds dict
            threshold: Percentile threshold for normal range (e.g., 95, 98)
            output_dir: Output directory path
            n_background: Number of background samples for SHAP
            max_anomalies: Maximum anomalies to analyze
            top_n_features: Top N features for global importance
            
        Returns:
            dict: {'excel_report': filepath}
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        print("="*60)
        print("STARTING ENHANCED SHAP EXPLAINABILITY PIPELINE")
        print("="*60)

        anomaly_indices = np.where(anomaly_flags)[0]
        
        # Filter anomalies by date if report_dates specified
        if report_dates is not None and original_df is not None:
            filtered_indices = self._filter_anomalies_by_date(
                anomaly_indices, original_df, date_col, report_dates
            )
            if len(filtered_indices) == 0:
                print(f"\nWARNING: No anomalies found for date(s): {report_dates}")
                print("Proceeding with all anomalies instead.")
            else:
                anomaly_indices = filtered_indices
                print(f"\nFiltered to {len(anomaly_indices)} anomalies for date(s): {report_dates}")
        
        n_anomalies = min(len(anomaly_indices), max_anomalies)
        anomaly_subset = test_sequences[anomaly_indices[:n_anomalies]]

        print(f"\nAnalyzing {n_anomalies} anomalies, top {top_n_features} features")

        # SHAP computation
        background = self._create_background_data(normal_sequences, n_background)
        shap_values, base_values = self.compute_shap_values(
            anomaly_subset, background, max_samples=n_anomalies
        )

        n_display = len(self.feature_names) if top_n_features == 'all' else top_n_features
        feature_ranking = self.global_feature_importance(shap_values, top_n=n_display)

        if top_n_features != 'all':
            feature_ranking = feature_ranking.head(top_n_features)

        # Add DQ dimensions to feature ranking
        feature_ranking['dq_dimension'] = feature_ranking['feature'].apply(self._get_dq_dimension)
        feature_ranking['criticality'] = feature_ranking['dq_dimension'].apply(
            self._get_severity_from_dq_dimension
        )

        # Calculate historical stats for features in anomalies
        unique_features_in_anomalies = set()
        for idx in range(n_anomalies):
            sample_shap = shap_values[idx]
            k = top_k_features if isinstance(top_k_features, int) else 3
            top_k_idx = np.argsort(np.abs(sample_shap))[-k:][::-1]
            for feat_idx in top_k_idx:
                unique_features_in_anomalies.add(feat_idx)
        
        # Get feature names that need stats
        feature_names_subset = [self.feature_names[i] for i in unique_features_in_anomalies]
        
        # Calculate stats from ORIGINAL RAW DATA (not scaled sequences)
        historical_stats = self._calculate_historical_stats_from_df(
            original_df, feature_names_subset, threshold
        )

        # Build structured DataFrames
        if original_df is not None:
            date_range = (
                original_df[date_col].min(),
                original_df[date_col].max()
            )
            top_3_features = feature_ranking.head(3)['feature'].tolist()
            
            # Tab 2: Anomaly Details (build FIRST to calculate real severity)
            k = top_k_features if isinstance(top_k_features, int) else 3
            anomalies_df = self.build_anomalies_dataframe(
                anomaly_subset=anomaly_subset,
                shap_values=shap_values,
                anomaly_indices=anomaly_indices[:n_anomalies],
                original_df=original_df,
                historical_stats=historical_stats,
                date_col=date_col,
                top_k=k,
                z_thresholds=z_score_thresholds
            )
            
            # Tab 1: Summary (build AFTER to use real severity from anomalies_df)
            summary_df = self.build_summary_dataframe(
                anomaly_count=len(anomaly_indices),
                total_samples=len(test_sequences),
                date_range=date_range,
                columns_analyzed=len(self.feature_names),
                columns_with_anomalies=len(unique_features_in_anomalies),
                top_features=top_3_features,
                threshold=threshold,
                anomalies_df=anomalies_df
            )

            # Tab 3: Feature Contribution
            feature_contrib_df = self.build_feature_contribution_dataframe(
                anomaly_subset=anomaly_subset,
                shap_values=shap_values,
                anomaly_indices=anomaly_indices[:n_anomalies],
                original_df=original_df,
                historical_stats=historical_stats,
                date_col=date_col,
                top_k=k,
                z_thresholds=z_score_thresholds
            )
        else:
            print("\nWARNING: original_df not provided, using legacy format")
            summary_df = None
            anomalies_df = None
            feature_contrib_df = None

        # Generate plots
        plot1_bytes = self._plot_to_bytes(feature_ranking)
        plot2_bytes = self._plot_to_bytes_summary(shap_values, anomaly_subset, len(feature_ranking))

        # Export to Excel
        excel_path = self._export_direct_to_excel_v2(
            summary_df=summary_df,
            feature_ranking=feature_ranking,
            anomalies_df=anomalies_df,
            feature_contrib_df=feature_contrib_df,
            output_dir=output_path,
            image_bytes_list=[plot1_bytes, plot2_bytes]
        )
        
        # Generate HTML report
        html_path = self._generate_html_report(
            summary_df=summary_df,
            anomalies_df=anomalies_df,
            feature_contrib_df=feature_contrib_df,
            feature_ranking=feature_ranking,
            output_dir=output_path
        )

        print(f"\n{'='*60}\nExcel report: {excel_path}")
        if html_path:
            print(f"HTML report: {html_path}")
        print('='*60)
        return {'excel_report': excel_path, 'html_report': html_path}

    def _plot_to_bytes(self, feature_ranking):
        """Generate plot directly to bytes."""
        fig, ax = plt.subplots(figsize=(10, 8))
        ax.barh(range(len(feature_ranking)), feature_ranking['mean_abs_shap'])
        ax.set_yticks(range(len(feature_ranking)))
        ax.set_yticklabels(feature_ranking['feature'])
        ax.set_xlabel('Mean |SHAP Value|', fontsize=12)
        ax.set_title('Feature Importance', fontsize=14, fontweight='bold')
        ax.invert_yaxis()
        plt.tight_layout()

        buf = BytesIO()
        plt.savefig(buf, format='png', dpi=300, bbox_inches='tight')
        plt.close()
        buf.seek(0)
        return buf

    def _plot_to_bytes_summary(self, shap_values, test_sequences, top_n):
        """Generate SHAP summary plot to bytes."""
        feature_values = test_sequences.mean(axis=1)
        plt.figure(figsize=(10, 8))
        shap.summary_plot(shap_values, feature_values,
                         feature_names=self.feature_names,
                         max_display=top_n, show=False)

        buf = BytesIO()
        plt.savefig(buf, format='png', dpi=300, bbox_inches='tight')
        plt.close()
        buf.seek(0)
        return buf

    def _get_html_template(self):
        """Return HTML template as embedded string."""
        return '''<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LSTM Anomaly Detection Report</title>
    <script src="https://cdn.plot.ly/plotly-2.18.0.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <style>
        :root {
            --primary-color: #667eea;
            --critical-color: #ff4444;
            --high-color: #ffaa00;
            --medium-color: #ffdd00;
            --low-color: #4444ff;
            --success-color: #70ad47;
            --text-color: #333;
            --bg-color: #f8f9fa;
            --border-color: #dee2e6;
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Arial, sans-serif;
            background: linear-gradient(135deg, var(--primary-color) 0%, #764ba2 100%);
            padding: 20px;
            color: var(--text-color);
        }
        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.2);
            overflow: hidden;
        }
        .header {
            background: linear-gradient(135deg, var(--primary-color) 0%, #764ba2 100%);
            color: white;
            padding: 30px 40px;
            text-align: center;
        }
        .header h1 { font-size: 2.5rem; margin-bottom: 10px; font-weight: 700; }
        .header p { font-size: 1rem; opacity: 0.9; }
        .metrics-container { padding: 30px; background: var(--bg-color); }
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
        }
        .metric-card {
            background: linear-gradient(135deg, var(--primary-color) 0%, #764ba2 100%);
            padding: 25px;
            border-radius: 10px;
            color: white;
            text-align: center;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            transition: transform 0.3s ease;
        }
        .metric-card:hover { transform: translateY(-5px); }
        .metric-value { font-size: 2.5rem; font-weight: bold; margin-bottom: 5px; }
        .metric-label { font-size: 0.9rem; opacity: 0.9; text-transform: uppercase; letter-spacing: 1px; }
        .metric-card.critical { background: linear-gradient(135deg, var(--critical-color) 0%, #cc0000 100%); }
        .metric-card.high { background: linear-gradient(135deg, var(--high-color) 0%, #ff8800 100%); }
        .metric-card.medium { background: linear-gradient(135deg, var(--medium-color) 0%, #ffcc00 100%); color: #333; }
        .tab-container { background: var(--bg-color); border-bottom: 2px solid var(--border-color); }
        .tabs { display: flex; list-style: none; overflow-x: auto; padding: 0 20px; }
        .tabs li { flex-shrink: 0; }
        .tab-link {
            display: block;
            padding: 18px 30px;
            color: #6c757d;
            text-decoration: none;
            font-weight: 500;
            border-bottom: 3px solid transparent;
            transition: all 0.3s ease;
            cursor: pointer;
            white-space: nowrap;
        }
        .tab-link:hover { color: var(--primary-color); background: rgba(102, 126, 234, 0.05); }
        .tab-link.active { color: var(--primary-color); border-bottom-color: var(--primary-color); background: white; }
        .tab-content { display: none; padding: 40px; animation: fadeIn 0.3s ease-in; }
        .tab-content.active { display: block; }
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        .section-title {
            font-size: 1.5rem;
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid var(--border-color);
        }
        .chart-container {
            background: white;
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        }
        .table-container {
            overflow-x: auto;
            background: white;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        }
        .data-table { width: 100%; border-collapse: collapse; font-size: 0.9rem; }
        .data-table thead tr {
            background: linear-gradient(135deg, var(--primary-color) 0%, #764ba2 100%);
            color: white;
            text-align: left;
            font-weight: 600;
        }
        .data-table th, .data-table td { padding: 14px 16px; }
        .data-table tbody tr { border-bottom: 1px solid #f0f0f0; transition: background 0.2s ease; }
        .data-table tbody tr:hover { background: var(--bg-color); }
        .badge-critical {
            background: var(--critical-color);
            color: white;
            padding: 5px 12px;
            border-radius: 20px;
            font-weight: 600;
            font-size: 0.85rem;
            text-transform: uppercase;
        }
        .badge-warning {
            background: var(--high-color);
            color: white;
            padding: 5px 12px;
            border-radius: 20px;
            font-weight: 600;
            font-size: 0.85rem;
            text-transform: uppercase;
        }
        .badge-unknown {
            background: var(--low-color);
            color: white;
            padding: 5px 12px;
            border-radius: 20px;
            font-weight: 600;
            font-size: 0.85rem;
            text-transform: uppercase;
        }
        .explanation-card {
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            border-left: 4px solid;
        }
        .explanation-card.critical { background: #fff5f5; border-left-color: var(--critical-color); }
        .explanation-card.warning { background: #fff9f0; border-left-color: var(--high-color); }
        .explanation-card.unknown { background: #fffef0; border-left-color: var(--medium-color); }
        .explanation-card h4 { margin-bottom: 10px; }
        @media (max-width: 768px) {
            .header h1 { font-size: 1.8rem; }
            .metrics-grid { grid-template-columns: 1fr; }
            .tab-content { padding: 20px; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1><i class="fas fa-chart-line"></i> LSTM Anomaly Detection Report</h1>
            <p>Generated: {{GENERATION_DATE}}</p>
            <p>Analysis Period: {{ANALYSIS_PERIOD}}</p>
        </div>
        <div class="metrics-container">{{METRICS_HTML}}</div>
        <div class="tab-container">
            <ul class="tabs">
                <li><a class="tab-link active" onclick="openTab(event, 'tab1')"><i class="fas fa-home"></i> Overview</a></li>
                <li><a class="tab-link" onclick="openTab(event, 'tab2')"><i class="fas fa-exclamation-triangle"></i> Anomaly Details</a></li>
                <li><a class="tab-link" onclick="openTab(event, 'tab3')"><i class="fas fa-comment-dots"></i> Business Explanations</a></li>
                <li><a class="tab-link" onclick="openTab(event, 'tab4')"><i class="fas fa-project-diagram"></i> Feature Contributions</a></li>
                <li><a class="tab-link" onclick="openTab(event, 'tab5')"><i class="fas fa-database"></i> Baseline Statistics</a></li>
            </ul>
        </div>
        <div style="background: white;">
            <div id="tab1" class="tab-content active">
                <h2 class="section-title">Executive Summary</h2>
                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 30px;">
                    <div class="chart-container">
                        <h3 style="color: #495057; margin-bottom: 15px;">Severity Distribution</h3>
                        <div id="chart1"></div>
                    </div>
                    <div class="chart-container">
                        <h3 style="color: #495057; margin-bottom: 15px;">Top Anomalous Features</h3>
                        <div id="chart2"></div>
                    </div>
                </div>
                <div class="chart-container">
                    <h3 style="color: #495057; margin-bottom: 15px;">Key Insights</h3>
                    {{KEY_INSIGHTS_HTML}}
                </div>
            </div>
            <div id="tab2" class="tab-content">
                <h2 class="section-title">Detected Anomalies</h2>
                <div class="table-container">{{ANOMALY_TABLE}}</div>
            </div>
            <div id="tab3" class="tab-content">
                <h2 class="section-title">Business-Friendly Explanations</h2>
                {{EXPLANATIONS_HTML}}
            </div>
            <div id="tab4" class="tab-content">
                <h2 class="section-title">SHAP Feature Contributions</h2>
                <div class="table-container">{{SHAP_TABLE}}</div>
                <div class="chart-container" style="margin-top: 30px;">
                    <h3 style="color: #495057; margin-bottom: 15px;">SHAP Value Distribution</h3>
                    <div id="chart3"></div>
                </div>
            </div>
            <div id="tab5" class="tab-content">
                <h2 class="section-title">Historical Baseline Statistics</h2>
                <div class="table-container">{{BASELINE_TABLE}}</div>
            </div>
        </div>
    </div>
    <script>
        function openTab(evt, tabId) {
            const tabContents = document.getElementsByClassName('tab-content');
            for (let i = 0; i < tabContents.length; i++) {
                tabContents[i].classList.remove('active');
            }
            const tabLinks = document.getElementsByClassName('tab-link');
            for (let i = 0; i < tabLinks.length; i++) {
                tabLinks[i].classList.remove('active');
            }
            document.getElementById(tabId).classList.add('active');
            evt.currentTarget.classList.add('active');
        }
        {{CHART_RENDERING_SCRIPTS}}
    </script>
</body>
</html>'''

    def _generate_html_report(self, summary_df, anomalies_df, feature_contrib_df, 
                              feature_ranking, output_dir):
        """
        Generate interactive HTML report from Excel DataFrames.
        
        Args:
            summary_df: Summary metrics DataFrame
            anomalies_df: Anomaly details DataFrame
            feature_contrib_df: Feature contribution DataFrame
            feature_ranking: Feature importance DataFrame
            output_dir: Output directory
            
        Returns:
            Path: HTML file path
        """
        print("\nGenerating interactive HTML report...")
        
        html_template = self._get_html_template()
        
        # Extract metrics from summary_df
        metrics = {}
        if summary_df is not None:
            for _, row in summary_df.iterrows():
                metrics[row['Metric']] = row['Value']
        
        # Generate metrics cards HTML
        metrics_html = f"""
        <div class="metrics-grid">
            <div class="metric-card">
                <div class="metric-value">{metrics.get('Total Anomalies Detected', 0)}</div>
                <div class="metric-label">Total Anomalies</div>
            </div>
            <div class="metric-card critical">
                <div class="metric-value">{metrics.get('Critical Anomalies', 0)}</div>
                <div class="metric-label">Critical</div>
            </div>
            <div class="metric-card high">
                <div class="metric-value">{metrics.get('High Anomalies', 0)}</div>
                <div class="metric-label">High Severity</div>
            </div>
            <div class="metric-card medium">
                <div class="metric-value">{metrics.get('Low Anomalies', 0)}</div>
                <div class="metric-label">Low Severity</div>
            </div>
        </div>
        """
        
        # Generate anomaly table
        anomaly_table_html = "<table class='data-table'><thead><tr>"
        if anomalies_df is not None and len(anomalies_df) > 0:
            # Headers
            for col in ['pipeline_id', 'Timestamp', 'Feature_Name', 'Severity', 
                       'Raw_Value', 'Expected_Value', 'Z-Score']:
                if col in anomalies_df.columns:
                    anomaly_table_html += f"<th>{col.replace('_', ' ').title()}</th>"
            anomaly_table_html += "</tr></thead><tbody>"
            
            # Rows (limit to 100 for performance)
            for _, row in anomalies_df.head(100).iterrows():
                anomaly_table_html += "<tr>"
                for col in ['pipeline_id', 'Timestamp', 'Feature_Name', 'Severity', 
                           'Raw_Value', 'Expected_Value', 'Z-Score']:
                    if col in anomalies_df.columns:
                        val = row[col]
                        if col == 'Severity':
                            badge_class = f"badge-{val.lower()}" if isinstance(val, str) else "badge-low"
                            anomaly_table_html += f"<td><span class='{badge_class}'>{val}</span></td>"
                        elif col in ['Raw_Value', 'Expected_Value', 'Z-Score']:
                            anomaly_table_html += f"<td>{val:.2f}</td>"
                        else:
                            anomaly_table_html += f"<td>{val}</td>"
                anomaly_table_html += "</tr>"
            anomaly_table_html += "</tbody></table>"
        else:
            anomaly_table_html = "<p>No anomalies detected</p>"
        
        # Generate SHAP table
        shap_table_html = "<table class='data-table'><thead><tr>"
        if feature_contrib_df is not None and len(feature_contrib_df) > 0:
            for col in ['pipeline_id', 'Feature_Name', 'Raw_Value', 'Normal_Range', 
                       'Contribution_Score', 'Z-Score']:
                if col in feature_contrib_df.columns:
                    shap_table_html += f"<th>{col.replace('_', ' ').title()}</th>"
            shap_table_html += "</tr></thead><tbody>"
            
            for _, row in feature_contrib_df.head(100).iterrows():
                shap_table_html += "<tr>"
                for col in ['pipeline_id', 'Feature_Name', 'Raw_Value', 'Normal_Range', 
                           'Contribution_Score', 'Z-Score']:
                    if col in feature_contrib_df.columns:
                        val = row[col]
                        if col in ['Raw_Value', 'Contribution_Score', 'Z-Score']:
                            shap_table_html += f"<td>{val:.4f}</td>"
                        else:
                            shap_table_html += f"<td>{val}</td>"
                shap_table_html += "</tr>"
            shap_table_html += "</tbody></table>"
        else:
            shap_table_html = "<p>No feature contributions available</p>"
        
        # Generate baseline table
        baseline_table_html = "<table class='data-table'><thead><tr>"
        baseline_table_html += "<th>Feature</th><th>Mean</th><th>Std</th><th>Normal Range</th><th>DQ Dimension</th>"
        baseline_table_html += "</tr></thead><tbody>"
        if feature_ranking is not None:
            for _, row in feature_ranking.head(20).iterrows():
                baseline_table_html += f"<tr><td>{row['feature']}</td>"
                baseline_table_html += f"<td>{row['mean_abs_shap']:.4f}</td>"
                baseline_table_html += f"<td>N/A</td><td>N/A</td>"
                baseline_table_html += f"<td>{row.get('dq_dimension', 'Unknown')}</td></tr>"
        baseline_table_html += "</tbody></table>"
        
        # Generate business explanations
        explanations_html = ""
        if anomalies_df is not None and 'Description' in anomalies_df.columns:
            unique_descs = anomalies_df.groupby(['Feature_Name', 'Severity', 'Description']).size().reset_index()
            for _, row in unique_descs.head(10).iterrows():
                severity = row['Severity'].lower() if isinstance(row['Severity'], str) else 'low'
                explanations_html += f"""
                <div class="explanation-card {severity}">
                    <h4>{row['Feature_Name']}</h4>
                    <p>{row['Description']}</p>
                </div>
                """
        
        # Key insights
        key_insights_html = "<ul style='line-height: 2;'>"
        if anomalies_df is not None:
            top_features = anomalies_df['Feature_Name'].value_counts().head(3)
            for feat, count in top_features.items():
                key_insights_html += f"<li><strong>{feat}</strong>: {count} anomalies detected</li>"
        key_insights_html += "</ul>"
        
        # Plotly charts
        charts_script = ""
        
        # Chart 1: Severity distribution
        if anomalies_df is not None and 'Severity' in anomalies_df.columns:
            severity_counts = anomalies_df['Severity'].value_counts()
            charts_script += f"""
            Plotly.newPlot('chart1', [{{
                type: 'pie',
                labels: {severity_counts.index.tolist()},
                values: {severity_counts.values.tolist()},
                marker: {{
                    colors: ['#ff4444', '#ffaa00', '#4444ff']
                }}
            }}], {{height: 300}});
            """
        
        # Chart 2: Top features bar chart
        if feature_ranking is not None:
            top_features = feature_ranking.head(10)
            charts_script += f"""
            Plotly.newPlot('chart2', [{{
                type: 'bar',
                x: {top_features['mean_abs_shap'].tolist()},
                y: {top_features['feature'].tolist()},
                orientation: 'h',
                marker: {{ color: '#667eea' }}
            }}], {{height: 400, yaxis: {{autorange: 'reversed'}}}});
            """
        
        # Chart 3: SHAP distribution
        if feature_contrib_df is not None and 'Contribution_Score' in feature_contrib_df.columns:
            charts_script += f"""
            Plotly.newPlot('chart3', [{{
                type: 'histogram',
                x: {feature_contrib_df['Contribution_Score'].tolist()},
                marker: {{ color: '#667eea' }}
            }}], {{height: 300, xaxis: {{title: 'SHAP Value'}}}});
            """
        
        # Chart 4: Time series (if timestamp available)
        if anomalies_df is not None and 'Timestamp' in anomalies_df.columns:
            charts_script += f"""
            Plotly.newPlot('chart4', [{{
                type: 'scatter',
                mode: 'markers',
                x: {anomalies_df['Timestamp'].astype(str).tolist()},
                y: {anomalies_df['Raw_Value'].tolist() if 'Raw_Value' in anomalies_df.columns else []},
                marker: {{ size: 8, color: '#ff4444' }},
                name: 'Anomalies'
            }}], {{height: 400, xaxis: {{title: 'Date'}}, yaxis: {{title: 'Value'}}}});
            """
        
        # Replace placeholders
        html_content = html_template.replace('{{GENERATION_DATE}}', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
        html_content = html_content.replace('{{ANALYSIS_PERIOD}}', str(metrics.get('Date Range', 'N/A')))
        html_content = html_content.replace('{{METRICS_HTML}}', metrics_html)
        html_content = html_content.replace('{{ANOMALY_TABLE}}', anomaly_table_html)
        html_content = html_content.replace('{{SHAP_TABLE}}', shap_table_html)
        html_content = html_content.replace('{{BASELINE_TABLE}}', baseline_table_html)
        html_content = html_content.replace('{{EXPLANATIONS_HTML}}', explanations_html)
        html_content = html_content.replace('{{KEY_INSIGHTS_HTML}}', key_insights_html)
        html_content = html_content.replace('{{CHART_RENDERING_SCRIPTS}}', charts_script)
        
        # Save HTML
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        html_path = Path(output_dir) / f'shap_analysis_{timestamp}.html'
        with open(html_path, 'w') as f:
            f.write(html_content)
        
        print(f"  HTML report generated: {html_path}")
        return html_path
    
    def send_report_via_email(self, excel_path, html_path, 
                              to_emails, subject=None, body=None,
                              smtp_server='smtp.gmail.com', smtp_port=587,
                              from_email=None, password=None):
        """
        Send Excel and HTML reports as email attachments.
        
        Args:
            excel_path: Path to Excel file
            html_path: Path to HTML file
            to_emails: List of recipient emails or single email string
            subject: Email subject (auto-generated if None)
            body: Email body (auto-generated if None)
            smtp_server: SMTP server address
            smtp_port: SMTP port
            from_email: Sender email
            password: Sender password or app-specific password
            
        Returns:
            bool: True if sent successfully
            
        Example:
            explainer.send_report_via_email(
                excel_path=results['excel_report'],
                html_path=results['html_report'],
                to_emails=['user@company.com', 'manager@company.com'],
                from_email='anomaly-alerts@company.com',
                password='your-app-password'
            )
        """
        import smtplib
        from email.mime.multipart import MIMEMultipart
        from email.mime.text import MIMEText
        from email.mime.base import MIMEBase
        from email import encoders
        from pathlib import Path
        
        print("\nPreparing email with report attachments...")
        
        # Convert single email to list
        if isinstance(to_emails, str):
            to_emails = [to_emails]
        
        # Auto-generate subject and body
        if subject is None:
            subject = f"LSTM Anomaly Detection Report - {datetime.now().strftime('%Y-%m-%d')}"
        
        if body is None:
            body = f"""
Hi Team,

Please find attached the LSTM anomaly detection report generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.

Report formats included:
- Excel (.xlsx) - Full data with all tabs
- HTML (.html) - Interactive dashboard with Plotly charts

You can open the HTML file directly in your browser for an interactive view.

Best regards,
Anomaly Detection System
            """
        
        # Create message
        msg = MIMEMultipart()
        msg['From'] = from_email
        msg['To'] = ', '.join(to_emails)
        msg['Subject'] = subject
        msg.attach(MIMEText(body, 'plain'))
        
        # Attach Excel
        if excel_path and Path(excel_path).exists():
            with open(excel_path, 'rb') as f:
                part = MIMEBase('application', 'octet-stream')
                part.set_payload(f.read())
                encoders.encode_base64(part)
                part.add_header('Content-Disposition', 
                               f'attachment; filename={Path(excel_path).name}')
                msg.attach(part)
                print(f"  Attached: {Path(excel_path).name}")
        
        # Attach HTML
        if html_path and Path(html_path).exists():
            with open(html_path, 'rb') as f:
                part = MIMEBase('application', 'octet-stream')
                part.set_payload(f.read())
                encoders.encode_base64(part)
                part.add_header('Content-Disposition', 
                               f'attachment; filename={Path(html_path).name}')
                msg.attach(part)
                print(f"  Attached: {Path(html_path).name}")
        
        # Send email
        try:
            server = smtplib.SMTP(smtp_server, smtp_port)
            server.starttls()
            server.login(from_email, password)
            server.sendmail(from_email, to_emails, msg.as_string())
            server.quit()
            print(f"  Email sent successfully to {len(to_emails)} recipient(s)")
            return True
        except Exception as e:
            print(f"  Failed to send email: {str(e)}")
            return False

    def _export_direct_to_excel_v2(self, summary_df, feature_ranking, anomalies_df,
                                    feature_contrib_df, output_dir, image_bytes_list):
        """
        Export structured DataFrames to Excel (new version).
        
        Args:
            summary_df: Summary DataFrame for Tab 1
            feature_ranking: Feature ranking DataFrame for Tab 2
            anomalies_df: Anomalies detail DataFrame for Tab 3
            feature_contrib_df: Feature contribution DataFrame for Tab 4
            output_dir: Output directory
            image_bytes_list: List of image BytesIO objects
            
        Returns:
            Path: Excel file path
        """
        from openpyxl.drawing.image import Image as ExcelImage

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = Path(output_dir) / f'shap_analysis_{timestamp}.xlsx'

        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            # Tab 1: Summary
            if summary_df is not None:
                summary_df.to_excel(writer, sheet_name='summary', index=False)
            
            # Tab 2: Anomalies Details
            if anomalies_df is not None:
                anomalies_df.to_excel(writer, sheet_name='Anomalies_details', index=False)
            
            # Tab 3: Feature Contribution Analysis
            if feature_contrib_df is not None:
                feature_contrib_df.to_excel(writer, sheet_name='feature_Contribution_analysis', index=False)
            
            # Tab 4: SHAP Feature Contribution (renamed from Feature Ranking)
            feature_ranking.to_excel(writer, sheet_name='shap_feat_contribution', index=False)

            # Tab 5: Visualizations
            workbook = writer.book
            viz_sheet = workbook.create_sheet('Visualizations')

            row = 1
            for img_bytes in image_bytes_list:
                img = ExcelImage(img_bytes)
                img.width = 600
                img.height = 480
                viz_sheet.add_image(img, f'A{row}')
                row += 30

        print(f"Excel report generated: {filepath}")
        return filepath

    # Keep old export function for backward compatibility
    def _export_direct_to_excel(self, summary_text, feature_ranking,
                                anomaly_details, output_dir, image_bytes_list):
        """Legacy export function (kept for backward compatibility)."""
        from openpyxl.drawing.image import Image as ExcelImage

        feature_ranking['dq_dimension'] = feature_ranking['feature'].apply(self._get_dq_dimension)
        feature_ranking['criticality'] = feature_ranking['dq_dimension'].apply(
            self._get_severity_from_dq_dimension
        )

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filepath = Path(output_dir) / f'shap_analysis_{timestamp}.xlsx'

        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            summary_df = pd.DataFrame({'Executive Summary': summary_text.strip().split('\n')})
            summary_df.to_excel(writer, sheet_name='Executive Summary', index=False)
            feature_ranking.to_excel(writer, sheet_name='Feature Ranking', index=False)
            anomaly_details.to_excel(writer, sheet_name='Anomaly Details', index=False)

            workbook = writer.book
            viz_sheet = workbook.create_sheet('Visualizations')

            row = 1
            for img_bytes in image_bytes_list:
                img = ExcelImage(img_bytes)
                img.width = 600
                img.height = 480
                viz_sheet.add_image(img, f'A{row}')
                row += 30

        print(f"Excel report generated: {filepath}")
        return filepath
