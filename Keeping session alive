import org.apache.spark.sql.DataFrame
import org.apache.spark.sql.functions._

// Assuming df is your DataFrame with columns col1, col2, col3
def findSecondHighestColumn(df: DataFrame): DataFrame = {
  val sortedCols = array_sort(array(df("col1"), df("col2"), df("col3")))
  
  // Get the second highest value (last but one in the sorted array)
  val secondHighestValue = sortedCols.getItem(sortedCols.size - 2)

  // Create a map from column names to their values
  val columnsMap = Map(
    "col1" -> df("col1"),
    "col2" -> df("col2"),
    "col3" -> df("col3")
  )

  // Find the column which contains the second highest value
  val secondHighestColumn = columnsMap.find { case (_, colValue) => colValue === secondHighestValue }.map(_._1)

  df.withColumn("second_highest_col", lit(secondHighestColumn))
}

// Usage
val updatedDf = findSecondHighestColumn(yourDataFrame)
===================

import org.apache.spark.sql.expressions.Window
import org.apache.spark.sql.functions._
import org.apache.spark.sql.DataFrame

def findSecondHighestColumn(df: DataFrame): DataFrame = {
  // Create an array of struct (column_name, value) and then explode it
  val dfLong = df.withColumn(
    "col_values",
    explode(array(
      struct(lit("col1") as "column_name", $"col1" as "value"),
      struct(lit("col2") as "column_name", $"col2" as "value"),
      struct(lit("col3") as "column_name", $"col3" as "value")
    ))
  ).select($"*", $"col_values.column_name", $"col_values.value")

  // Define a window partitioned by original row identifiers and ordered by value
  val windowSpec = Window.partitionBy("id").orderBy($"value".desc) // Replace "id" with your row identifier

  // Rank the values and filter for rank 2
  val dfRanked = dfLong.withColumn("rank", rank().over(windowSpec))
                      .filter($"rank" === 2)

  // Join back with the original DataFrame to get the column name of the second highest value
  val result = df.join(dfRanked, Seq("id"), "left") // Replace "id" with your row identifier
                 .select(df.columns.map(df(_)) :+ dfRanked("column_name"): _*)

  result
}

// Usage
val updatedDf = findSecondHighestColumn(yourDataFrame)

