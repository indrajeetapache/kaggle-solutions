import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.DataFrame

val spark = SparkSession.builder.appName("Read Header Trailer Generically").getOrCreate()

// User input flags
val readHeader = true // Set to true or false based on user input
val readTrailer = true // Set to true or false based on user input

// Function to read header and/or trailer from a single file
def readHeaderTrailer(path: String): DataFrame = {
  val rdd = spark.sparkContext.textFile(path)
  
  val header = if (readHeader) Some(rdd.first()) else None
  val trailer = if (readTrailer) Some(rdd.takeOrdered(1)(Ordering.String.reverse).head) else None
  
  val headerTrailerSeq = Seq(header, trailer).flatten // This will create a Seq[String] with only the present elements
  val headerTrailerRDD = spark.sparkContext.parallelize(headerTrailerSeq)
  spark.createDataFrame(headerTrailerRDD.map(Tuple1.apply)).toDF("value")
}

// If you have multiple files and want to apply this to all files
val paths = Array("path_to_your_file_1.txt", "path_to_your_file_2.txt", "path_to_your_file_n.txt") // replace with actual paths
val headerTrailerDFs = paths.map(readHeaderTrailer)

// Combine all DataFrames into one
val combinedDF = headerTrailerDFs.reduce(_ union _)

// Show the result or process further as needed
combinedDF.show(false)

// Stop the Spark session
spark.stop()


